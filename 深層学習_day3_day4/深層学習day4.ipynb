{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"深層学習day4.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyOiLJKWOdT69eDJowQg5rPy"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"81FvQ4SS4x0_"},"source":["# 深層学習day4  \n","## 強化学習"]},{"cell_type":"markdown","metadata":{"id":"maVWUKP25MZm"},"source":["- 強化学習とは  \n","長期的に報酬を最大化できるように環境のなかで行動を選択できるエージェントを作ることを目標とする機械学習の一分野。  \n","行動の結果として得られる報酬をもとに、行動を決定する原理（ルール）を改善していく。  \n","この数年で急速に研究が進んでいる（AlphaGoから？）  \n","優れた方策を見つけることが目標。  \n","必要とされる計算量が多く、以前は困難であったが、方法の発展と計算能力の発展で実現可能になってきた。\n","- 強化学習の枠組み  \n","エージェントと環境を設定する。  \n","エージェントは、方策に従って行動をする。その結果環境が変化する。その結果、を報酬として受け取る。  \n","- 応用例  \n","環境：会社の販売促進部  \n","エージェント:プロフィールと購入履歴に基づいて、キャンペーンメールを送る顧客を決めるソフトウェア。  \n","行動:顧客ごとに送信、非送信の二つの行動を選ぶ。  \n","報酬:キャンペーンコストと売上による利益増減を報酬とする。  \n","- 学習の進め方  \n","過去の知識に基づく行動と確率的行動を組み合わせて行動を選択する。  \n","- 強化学習の数学表現  \n","方策について、方策関数: π(s, a)を置く。  \n","報酬について、行動価値関数: Q(s, a)を置く。特定の方策関数で試行を繰り返したときに、どのような報酬が得られるかを反映する。  \n","これらを学習する。  \n","- Q学習  \n","行動価値関数を、行動する毎に更新することにより学習を進める方法。  \n","- 関数近似法  \n","価値関数や方策関数を関数近似する手法のこと。  \n","以前は行動をテーブルで持っていた。  \n","現在は、テーブルをNN(要するに関数の一種として）を使う方法がとられることが多い。  \n","- 価値関数の種類  \n"," - 行動価値関数  \n"," 状態とエージェントの行動を合わせて規定される。\n"," - 状態価値関数  \n"," 環境の状態によって規定される。\n","\n","- 方策関数  \n","ある状態でどのような行動を採るのかの確率を与える関数。  \n","- 方策関数の学習  \n","方策反復法：方策をモデル化して最適化する。  \n","$\\pi (s, a|\\theta )$の重みθを学習させていく。  \n","$$\n","\\theta ^{(t+1)} = \\theta ^{(t)} + \\epsilon \\nabla J(\\theta )\n","$$  \n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"ETSBWPvkPUfk"},"source":["ここで、DQNの簡単な実装を試みる。  \n","コードとしては、https://qiita.com/sugulu_Ogawa_ISID/items/bc7c70e6658f204f85f9  を参考にした。"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hkLVYqRtBaC6","executionInfo":{"status":"ok","timestamp":1626601802924,"user_tz":-540,"elapsed":3716,"user":{"displayName":"石居拓己","photoUrl":"","userId":"06001050725637052584"}},"outputId":"2a9e0ec4-8e3b-404d-a031-18330ec80e14"},"source":["!pip install pydot"],"execution_count":32,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: pydot in /usr/local/lib/python3.7/dist-packages (1.3.0)\n","Requirement already satisfied: pyparsing>=2.1.4 in /usr/local/lib/python3.7/dist-packages (from pydot) (2.4.7)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I6nIXlCjBfky","executionInfo":{"status":"ok","timestamp":1626601867183,"user_tz":-540,"elapsed":5202,"user":{"displayName":"石居拓己","photoUrl":"","userId":"06001050725637052584"}},"outputId":"0539b34f-82e7-4a4f-9c07-fa6d7d5b5679"},"source":["!pip install graphviz\n","!pip install pydotplus"],"execution_count":36,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (0.10.1)\n","Requirement already satisfied: pydotplus in /usr/local/lib/python3.7/dist-packages (2.0.2)\n","Requirement already satisfied: pyparsing>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from pydotplus) (2.4.7)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dqWzDD29PSEk","executionInfo":{"status":"ok","timestamp":1626601895755,"user_tz":-540,"elapsed":225,"user":{"displayName":"石居拓己","photoUrl":"","userId":"06001050725637052584"}}},"source":["import gym\n","import numpy as np\n","import time\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.optimizers import Adam\n","from keras.utils.vis_utils import plot_model\n","from collections import deque\n","from gym import wrappers  \n","from keras import backend as K\n","import tensorflow as tf"],"execution_count":39,"outputs":[]},{"cell_type":"code","metadata":{"id":"zBS3wQ8iQIo_","executionInfo":{"status":"ok","timestamp":1626601901763,"user_tz":-540,"elapsed":228,"user":{"displayName":"石居拓己","photoUrl":"","userId":"06001050725637052584"}}},"source":["def huberloss(y_true, y_pred):\n","    err = y_true - y_pred\n","    cond = K.abs(err) < 1.0\n","    L2 = 0.5 * K.square(err)\n","    L1 = (K.abs(err) - 0.5)\n","    loss = tf.where(cond, L2, L1)\n","    return K.mean(loss)"],"execution_count":40,"outputs":[]},{"cell_type":"code","metadata":{"id":"mTJyDc09QIxS","executionInfo":{"status":"ok","timestamp":1626601904951,"user_tz":-540,"elapsed":2,"user":{"displayName":"石居拓己","photoUrl":"","userId":"06001050725637052584"}}},"source":["class QNetwork:\n","    def __init__(self, learning_rate=0.01, state_size=4, action_size=2, hidden_size=10):\n","        self.model = Sequential()\n","        self.model.add(Dense(hidden_size, activation='relu', input_dim=state_size))\n","        self.model.add(Dense(hidden_size, activation='relu'))\n","        self.model.add(Dense(action_size, activation='linear'))\n","        self.optimizer = Adam(lr=learning_rate)  \n","        \n","        self.model.compile(loss=huberloss, optimizer=self.optimizer)\n","\n","    def replay(self, memory, batch_size, gamma, targetQN):\n","        inputs = np.zeros((batch_size, 4))\n","        targets = np.zeros((batch_size, 2))\n","        mini_batch = memory.sample(batch_size)\n","\n","        for i, (state_b, action_b, reward_b, next_state_b) in enumerate(mini_batch):\n","            inputs[i:i + 1] = state_b\n","            target = reward_b\n","\n","            if not (next_state_b == np.zeros(state_b.shape)).all(axis=1):\n","                retmainQs = self.model.predict(next_state_b)[0]\n","                next_action = np.argmax(retmainQs) \n","                target = reward_b + gamma * targetQN.model.predict(next_state_b)[0][next_action]\n","\n","            targets[i] = self.model.predict(state_b) \n","            targets[i][action_b] = target \n","\n","        self.model.fit(inputs, targets, epochs=1, verbose=0)  "],"execution_count":41,"outputs":[]},{"cell_type":"code","metadata":{"id":"iJM9nqweQI5j","executionInfo":{"status":"ok","timestamp":1626601908363,"user_tz":-540,"elapsed":4,"user":{"displayName":"石居拓己","photoUrl":"","userId":"06001050725637052584"}}},"source":["class Memory:\n","    def __init__(self, max_size=1000):\n","        self.buffer = deque(maxlen=max_size)\n","\n","    def add(self, experience):\n","        self.buffer.append(experience)\n","\n","    def sample(self, batch_size):\n","        idx = np.random.choice(np.arange(len(self.buffer)), size=batch_size, replace=False)\n","        return [self.buffer[ii] for ii in idx]\n","\n","    def len(self):\n","        return len(self.buffer)"],"execution_count":42,"outputs":[]},{"cell_type":"code","metadata":{"id":"imxG5Bf0QhGH","executionInfo":{"status":"ok","timestamp":1626601927628,"user_tz":-540,"elapsed":229,"user":{"displayName":"石居拓己","photoUrl":"","userId":"06001050725637052584"}}},"source":["class Actor:\n","    def get_action(self, state, episode, mainQN): \n","        epsilon = 0.001 + 0.9 / (1.0+episode)\n","\n","        if epsilon <= np.random.uniform(0, 1):\n","            retTargetQs = mainQN.model.predict(state)[0]\n","            action = np.argmax(retTargetQs)\n","        else:\n","            action = np.random.choice([0, 1])\n","\n","        return action"],"execution_count":44,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F051NTa8QhS7","outputId":"8e06d3ef-4a1f-4448-e9c8-028e5ec509e5"},"source":["LENDER_MODE = 1\n","\n","env = gym.make('CartPole-v0')\n","num_episodes = 299 \n","max_number_of_steps = 200 \n","goal_average_reward = 195 \n","num_consecutive_iterations = 10 \n","total_reward_vec = np.zeros(num_consecutive_iterations)  \n","gamma = 0.99\n","islearned = 0 \n","isrender = 0\n","\n","hidden_size = 16              \n","learning_rate = 0.00001        \n","memory_size = 10000   \n","batch_size = 32        \n","\n","mainQN = QNetwork(hidden_size=hidden_size, learning_rate=learning_rate) \n","targetQN = QNetwork(hidden_size=hidden_size, learning_rate=learning_rate) \n","memory = Memory(max_size=memory_size)\n","actor = Actor()\n","\n","for episode in range(num_episodes): \n","    env.reset()  \n","    state, reward, done, _ = env.step(env.action_space.sample())  \n","    state = np.reshape(state, [1, 4])   \n","    episode_reward = 0\n","\n","\n","    targetQN.model.set_weights(mainQN.model.get_weights())\n","\n","    for t in range(max_number_of_steps + 1):  \n","        if (islearned == 1) and LENDER_MODE:  \n","            env.render()\n","            time.sleep(0.1)\n","            print(state[0, 0])  \n","\n","        action = actor.get_action(state, episode, mainQN)   \n","        next_state, reward, done, info = env.step(action)   \n","        next_state = np.reshape(next_state, [1, 4]) \n","\n","        if done:\n","            next_state = np.zeros(state.shape)\n","            if t < 195:\n","                reward = -1 \n","            else:\n","                reward = 1 \n","        else:\n","            reward = 0 \n","\n","        episode_reward += 1\n","\n","        memory.add((state, action, reward, next_state)) \n","        state = next_state\n","\n","\n","        if (memory.len() > batch_size) and not islearned:\n","            mainQN.replay(memory, batch_size, gamma, targetQN)\n","\n","        targetQN.model.set_weights(mainQN.model.get_weights())\n","\n","        if done:\n","            total_reward_vec = np.hstack((total_reward_vec[1:], episode_reward)) \n","            print('%d Episode finished after %f time steps / mean %f' % (episode, t + 1, total_reward_vec.mean()))\n","            break\n","\n","    if total_reward_vec.mean() >= goal_average_reward:\n","        print('Episode %d train agent successfuly!' % episode)\n","        islearned = 1\n","        if isrender == 0:\n","            isrender = 1\n","\n","            env = wrappers.Monitor(env, './movie/cartpoleDDQN')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"],"name":"stderr"},{"output_type":"stream","text":["0 Episode finished after 37.000000 time steps / mean 3.700000\n","1 Episode finished after 24.000000 time steps / mean 6.100000\n","2 Episode finished after 21.000000 time steps / mean 8.200000\n","3 Episode finished after 39.000000 time steps / mean 12.100000\n","4 Episode finished after 42.000000 time steps / mean 16.300000\n","5 Episode finished after 34.000000 time steps / mean 19.700000\n","6 Episode finished after 41.000000 time steps / mean 23.800000\n","7 Episode finished after 41.000000 time steps / mean 27.900000\n","8 Episode finished after 46.000000 time steps / mean 32.500000\n","9 Episode finished after 94.000000 time steps / mean 41.900000\n","10 Episode finished after 25.000000 time steps / mean 40.700000\n","11 Episode finished after 59.000000 time steps / mean 44.200000\n","12 Episode finished after 24.000000 time steps / mean 44.500000\n","13 Episode finished after 42.000000 time steps / mean 44.800000\n","14 Episode finished after 52.000000 time steps / mean 45.800000\n","15 Episode finished after 24.000000 time steps / mean 44.800000\n","16 Episode finished after 57.000000 time steps / mean 46.400000\n","17 Episode finished after 41.000000 time steps / mean 46.400000\n","18 Episode finished after 40.000000 time steps / mean 45.800000\n","19 Episode finished after 46.000000 time steps / mean 41.000000\n","20 Episode finished after 26.000000 time steps / mean 41.100000\n","21 Episode finished after 68.000000 time steps / mean 42.000000\n","22 Episode finished after 73.000000 time steps / mean 46.900000\n","23 Episode finished after 28.000000 time steps / mean 45.500000\n","24 Episode finished after 25.000000 time steps / mean 42.800000\n","25 Episode finished after 53.000000 time steps / mean 45.700000\n","26 Episode finished after 37.000000 time steps / mean 43.700000\n","27 Episode finished after 23.000000 time steps / mean 41.900000\n","28 Episode finished after 47.000000 time steps / mean 42.600000\n","29 Episode finished after 43.000000 time steps / mean 42.300000\n","30 Episode finished after 25.000000 time steps / mean 42.200000\n","31 Episode finished after 33.000000 time steps / mean 38.700000\n","32 Episode finished after 25.000000 time steps / mean 33.900000\n","33 Episode finished after 24.000000 time steps / mean 33.500000\n","34 Episode finished after 49.000000 time steps / mean 35.900000\n","35 Episode finished after 35.000000 time steps / mean 34.100000\n","36 Episode finished after 30.000000 time steps / mean 33.400000\n","37 Episode finished after 30.000000 time steps / mean 34.100000\n","38 Episode finished after 22.000000 time steps / mean 31.600000\n","39 Episode finished after 57.000000 time steps / mean 33.000000\n","40 Episode finished after 23.000000 time steps / mean 32.800000\n","41 Episode finished after 37.000000 time steps / mean 33.200000\n","42 Episode finished after 69.000000 time steps / mean 37.600000\n","43 Episode finished after 47.000000 time steps / mean 39.900000\n","44 Episode finished after 37.000000 time steps / mean 38.700000\n","45 Episode finished after 29.000000 time steps / mean 38.100000\n","46 Episode finished after 103.000000 time steps / mean 45.400000\n","47 Episode finished after 24.000000 time steps / mean 44.800000\n","48 Episode finished after 39.000000 time steps / mean 46.500000\n","49 Episode finished after 26.000000 time steps / mean 43.400000\n","50 Episode finished after 31.000000 time steps / mean 44.200000\n","51 Episode finished after 17.000000 time steps / mean 42.200000\n","52 Episode finished after 20.000000 time steps / mean 37.300000\n","53 Episode finished after 24.000000 time steps / mean 35.000000\n","54 Episode finished after 29.000000 time steps / mean 34.200000\n","55 Episode finished after 37.000000 time steps / mean 35.000000\n","56 Episode finished after 26.000000 time steps / mean 27.300000\n","57 Episode finished after 41.000000 time steps / mean 29.000000\n","58 Episode finished after 51.000000 time steps / mean 30.200000\n","59 Episode finished after 50.000000 time steps / mean 32.600000\n","60 Episode finished after 23.000000 time steps / mean 31.800000\n","61 Episode finished after 22.000000 time steps / mean 32.300000\n","62 Episode finished after 18.000000 time steps / mean 32.100000\n","63 Episode finished after 43.000000 time steps / mean 34.000000\n","64 Episode finished after 23.000000 time steps / mean 33.400000\n","65 Episode finished after 52.000000 time steps / mean 34.900000\n","66 Episode finished after 22.000000 time steps / mean 34.500000\n","67 Episode finished after 36.000000 time steps / mean 34.000000\n","68 Episode finished after 45.000000 time steps / mean 33.400000\n","69 Episode finished after 19.000000 time steps / mean 30.300000\n","70 Episode finished after 19.000000 time steps / mean 29.900000\n","71 Episode finished after 30.000000 time steps / mean 30.700000\n","72 Episode finished after 43.000000 time steps / mean 33.200000\n","73 Episode finished after 57.000000 time steps / mean 34.600000\n","74 Episode finished after 26.000000 time steps / mean 34.900000\n","75 Episode finished after 22.000000 time steps / mean 31.900000\n","76 Episode finished after 22.000000 time steps / mean 31.900000\n","77 Episode finished after 82.000000 time steps / mean 36.500000\n","78 Episode finished after 44.000000 time steps / mean 36.400000\n","79 Episode finished after 23.000000 time steps / mean 36.800000\n","80 Episode finished after 22.000000 time steps / mean 37.100000\n","81 Episode finished after 20.000000 time steps / mean 36.100000\n","82 Episode finished after 25.000000 time steps / mean 34.300000\n","83 Episode finished after 71.000000 time steps / mean 35.700000\n","84 Episode finished after 46.000000 time steps / mean 37.700000\n","85 Episode finished after 25.000000 time steps / mean 38.000000\n","86 Episode finished after 31.000000 time steps / mean 38.900000\n","87 Episode finished after 26.000000 time steps / mean 33.300000\n","88 Episode finished after 43.000000 time steps / mean 33.200000\n","89 Episode finished after 24.000000 time steps / mean 33.300000\n","90 Episode finished after 27.000000 time steps / mean 33.800000\n","91 Episode finished after 50.000000 time steps / mean 36.800000\n","92 Episode finished after 22.000000 time steps / mean 36.500000\n","93 Episode finished after 103.000000 time steps / mean 39.700000\n","94 Episode finished after 75.000000 time steps / mean 42.600000\n","95 Episode finished after 63.000000 time steps / mean 46.400000\n","96 Episode finished after 20.000000 time steps / mean 45.300000\n","97 Episode finished after 18.000000 time steps / mean 44.500000\n","98 Episode finished after 36.000000 time steps / mean 43.800000\n","99 Episode finished after 49.000000 time steps / mean 46.300000\n","100 Episode finished after 50.000000 time steps / mean 48.600000\n","101 Episode finished after 38.000000 time steps / mean 47.400000\n","102 Episode finished after 19.000000 time steps / mean 47.100000\n","103 Episode finished after 24.000000 time steps / mean 39.200000\n","104 Episode finished after 30.000000 time steps / mean 34.700000\n","105 Episode finished after 25.000000 time steps / mean 30.900000\n","106 Episode finished after 22.000000 time steps / mean 31.100000\n","107 Episode finished after 34.000000 time steps / mean 32.700000\n","108 Episode finished after 51.000000 time steps / mean 34.200000\n","109 Episode finished after 30.000000 time steps / mean 32.300000\n","110 Episode finished after 21.000000 time steps / mean 29.400000\n","111 Episode finished after 29.000000 time steps / mean 28.500000\n","112 Episode finished after 36.000000 time steps / mean 30.200000\n","113 Episode finished after 45.000000 time steps / mean 32.300000\n","114 Episode finished after 37.000000 time steps / mean 33.000000\n","115 Episode finished after 24.000000 time steps / mean 32.900000\n","116 Episode finished after 21.000000 time steps / mean 32.800000\n","117 Episode finished after 17.000000 time steps / mean 31.100000\n","118 Episode finished after 31.000000 time steps / mean 29.100000\n","119 Episode finished after 48.000000 time steps / mean 30.900000\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"UZ5uBjVm44Yz"},"source":["## AlphaGo"]},{"cell_type":"markdown","metadata":{"id":"Sf3amuW92ilN"},"source":["- AlphaGo Lee  \n","2つのNNを使う。PolicyNet(方策関数)とValueNet(価値関数)  \n","- PolicyNet  \n","19x19の盤面の状況が入力になる。各交点に対して、48のチャンネルを持つ。石の種類や呼吸点など。2次元情報なので、畳み込みをする。出力層の活性化はSoftMax関数。  \n","- ValueNet  \n","policyNetに類似だが、出力層の活性化はtanh関数（-1～1の間の出力）。\n","- AlphaGoの学習  \n"," 1. 教師あり学習を実施  \n"," 過去の盤面を教師データとして利用する。  \n"," 2. 強化学習でPolicyNetを学習  \n"," 3. 強化学習でValueNetを学習\n","工夫として、RollOutPolicyを使う。  \n","- RallOutPolicy  \n","PolicyNetの計算量の多さを解決するための手法。線形の方策関数。PolicyNetよりも1000倍速い。1.の教師あり学習の時に使う。  \n","- モンテカルロ木探索  \n","各プレイヤーの選択を枝としてTree構造を持たせて、不要な枝を切り取りながら探索を行う。また、この際確率的な処理を行って計算量を抑制する。  \n","- AlphaGo Zero  \n","教師あり学習を行わず、強化学習のみで作成。（つまり、過去の人間の棋譜を用いない）  \n","特徴量として、石の配置のみを入力にとる。  \n","PolicyNetとValueNetを1つのネットワークに統合。  \n","ResidualNetを導入した。  \n","モンテカルロ木探索からRollOutシミュレーションをなくした。  \n","- PolicyValueNet  \n","NNの途中の層で、処理が分岐する。分岐の手前にあるのが、ResidualNetwork。  \n","- ResidualNetwok  \n","ネットワークに入る前にショートカットするような処理を加える。勾配の爆発/消失を抑制できる。層数の異なるNetworkを組み合わせているのと同様の効果があり、アンサンブル効果が得られる。ランダムツリーと似たようなもの。  \n"]},{"cell_type":"markdown","metadata":{"id":"mNNd58c344g4"},"source":["## 軽量化・高速化技術"]},{"cell_type":"markdown","metadata":{"id":"qwVqlqXQG1KG"},"source":["- 分散深層学習  \n","深層学習では多くのデータを使用する。毎年新たなアルゴリズムが提案され、扱うデータの量、計算量が爆発的に増えている（毎年10倍のペース）  \n","これに対応するために、データ並列化、モデル並列化、GPUによる高速技術は不可欠である。  \n","- データ並列化  \n","親も出るを各ワーカーに子モデルとしてコピー。データを分割し、各ワーカーごとに計算させる。  \n","要するに、パソコンを何台も買ってきて計算させるような手法。  \n","同期型と非同期型の2種類がある。  \n","同期型　：各ワーカーが出した勾配を平均して親モデルを更新する。これを繰り返す。  \n","非同期型：学習が終わったワーカーからすぐにパラメータを更新していく。（ほかのワーカーを待たない）  \n","同期型か非同期型かは使いどころ。全コンピュータの状況を自由に制御できる場合は、同期型が使われる。  \n","- モデル並列化  \n","一つの大きなモデルを複数に分割して別のワーカーで学習を進める。  \n","モデルが大きいときはモデル並列化を、データが大きいときはデータ並列化をすると良い。  \n","- CPUとGPU  \n","CPUは複雑な処理ができる。高性能なコアが少数。  \n","GPUは簡単な処理が得意。CPUより低性能なコアが多数ある。NNの学習は各計算が単純なので高速化できる。  \n","- 開発環境  \n","CUDAとOpenCLがあるが、CUDAが主流。NVIDIAが開発しているGPUで使用可能。我々はTensorFlowのようなフレームワークの使い方を覚えれば、GPUを利用することができる。  \n","- 量子化（Quantization）  \n","大規模なNNだと多くのメモリと演算処理が必要。64bit浮動小数点を32bitなど解制度に落としてメモリと演算処理を節約する。ただし、制度を犠牲にすることになる。  \n","ではどの精度を選ぶべきか⇒経験的に半精度にするのが良い。（それほどNNの質は落ちないが、計算速度は速くなる）  \n","- 蒸留  \n","学習済みの高精度モデルを流用して、軽量なモデルを作る。  \n","教師モデル（優秀なモデル）と生徒モデル（制度はそこそこだが、軽量）を持つ。  \n","- プルーニング  \n","必要なパラメータのみ残して、不要なものは削り取ってしまう。重みが0に近いニューロンを削減して再学習を行う。例えば、「重みw<0.1を削る」など。パラメータの99.5%くらいまで削減しても、それほど精度が下がらない。  \n","  \n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"40nn1R2T44nL"},"source":["## 応用モデル"]},{"cell_type":"markdown","metadata":{"id":"bsYZJts8YEzW"},"source":["- MobileNets  \n","画像認識のモデル。あまり計算量を増やさずに、そこそこの精度を出そうというモデル。畳み込み演算に工夫がある。  \n","Depthwise ConvolutionとPointwise Convolutionの組み合わせで軽量化を実現。  \n","HxWxKxKxCxMの計算量がHxWxCxKxK + HxWxCxMで実施できる。\n","- Depthwise Convolution  \n","入力マップのチャネルごとに畳み込みを実施する。出力マップをそれらと結合（入力マップのチャネル数と同じになる。  \n","- Pointwise Convolution  \n","カーネルサイズを1x1に固定する。これで、チャンネル数を任意に調整できる。  \n","- DenseNet  \n","画像認識のネットワーク。DenseBlockを挟むことが特徴。  \n","- Dense Block  \n","前のレイヤーの出力に、入力特徴マップを足し合わせる。結果チャンネル数が増えていく。  \n","Dense Blockではレイヤーがどんどん増えてしまうので、Transition LayerをDense Blockの間に挟む。Transition LayerはConvolutionとPoolingで構成される。  \n","- DenseNetとResNetの違い  \n","ResNetは前一層の入力のみを後方の層へ入力  \n","DenseNetでは前方の各層からの出力すべてが後方の層の入力として用いられる。  \n","- BatchNorm  \n","ミニバッチ単位で正規化する。ミニバッチのサイズは計算機に依存して変わってしまう。統一した効果を負うのが難しい。そのため、あまり採用したくない方法。  \n","- Layer Norm  \n","それぞれのsampleのすべてのpixelsが同一分布になるように正規化。  \n","- Instance Norm  \n","更に、layer normに加えて、さらにchannelも同一分布に従うように正規化。  \n","- Wavenet  \n","音声の生成モデル。畳み込み演算を利用する。  \n","層が深くなるにつれて畳み込むリンクを離す。受容野を簡単に増やすことができるという利点がある。（時間的にかなりの範囲をフォローすることができるようになる）  \n","Dilated causal Convolutionと呼ぶ。  \n","- DCGAN  \n","※ 適切なレポート記載場所がなかったので、応用モデルに入れた。  \n","Generator(生成器)とDiscriminator(識別器)を用いたモデル。  \n","データの生成のために用いる。（例えば人の顔の写真画像）  \n","Generator: 乱数からデータを生成する。  \n","Discriminator: 真データであるか、Generatorが作ったデータであるかを識別する。  \n","GeneratorとDiscriminatorの間の2プレイヤーミニマックスゲームとみることができる。  \n","- 価値関数  \n","バイナリークロスエントロピーを価値関数として用いる。  \n","- 最適化方法  \n","Discriminatorの更新ではGeneratorのパラメータを固定する。真データと(Generatorによる）生成データをmずつ（等数）サンプル誌、Discriminatorのパラメータθdを勾配上昇法で更新する。(Discriminatorは敵対的にふるまうので、勾配上昇になる）  \n","Generatorの更新では、Discriminatorのパラメータを固定する。生成データをm個ずつサンプルし、θgを勾配降下法で更新する。  \n","- Generatorが本物のようなデータを生成している状況とは？  \n","pg = pdataの時に、価値関数が最大化される（最適化される）ようになっていればよい。  \n","つまり、pg = pdataが  \n","$$\n","    \\min_G \\max_D V(D,G) = \\mathbb{E}_{x~p_{data}}[\\log D(x)] + \\mathbb{E}_{z~p_z(z)}[\\log (1-D(G(z)))]\n","$$  \n","を与えることを示せればよい。\n","まずは価値関数V(D,G)を最大化する条件を求める。微分して変形することで、  \n","$$\n","    D = \\frac{p_{data}(x)}{p_{data}(x) + p_g (x)}\n","$$\n","のとき最大になることがわかり、代入すると  \n","$$\n","    V = \\mathbb{E}_{x^p_{data}}\\log\\left[\\frac{p_{data}(x)}{p_{data}(x)+p_g (x)}\\right] + \\mathbb{E}_{x^p_{data}}\\log\\left[\\frac{p_g(x)}{p_{data}(x)+p_g (x)}\\right]\\\\\n","    = 2JS(p_{data} || p_g)-2\\log 2\n","$$\n","が最大条件を満たす。JSはJSダイバージェンスを意味する。これは、分布が一致する際に最小値0を取ることが知られている。  \n","- DCGAN(Deep Convolutional GAN)とは  \n","Ganを利用した画像生成モデル。  \n","Generator:Pooling層の代わりに転置畳み込み層を使用。最終層はtanh、その他はReluで活性化。  \n","Discriminator:Pooling層の代わりに畳み込み層を使用。Leaky Reluで活性化。最終層はSigmoidで活性化。  \n","共通事項: 中間層に全結合層を使わない。バッチノーマライゼーションを適用する。  \n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"So06Wg8LJJdm"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"Sba7kwPjJJmP"},"source":["ここでは、具体例としてDenseNetを実装してみる。  \n","なお、https://qiita.com/koshian2/items/01bd9f08444799625607  を参考にした。  \n"]},{"cell_type":"code","metadata":{"id":"IINjTcoRJIe2","executionInfo":{"status":"ok","timestamp":1626587726415,"user_tz":-540,"elapsed":226,"user":{"displayName":"石居拓己","photoUrl":"","userId":"06001050725637052584"}}},"source":["from keras.layers import Conv2D, Activation, BatchNormalization, Concatenate, AveragePooling2D, Input, GlobalAveragePooling2D, Dense\n","from keras.models import Model\n","from keras.optimizers import Adam\n","from keras.datasets import cifar10\n","from keras.utils.np_utils import to_categorical\n","from keras.preprocessing.image import ImageDataGenerator\n","import pickle\n","import numpy as np"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"sI5LCA1AJj3x","executionInfo":{"status":"ok","timestamp":1626588365423,"user_tz":-540,"elapsed":239,"user":{"displayName":"石居拓己","photoUrl":"","userId":"06001050725637052584"}}},"source":["class DenseNetSimple:\n","    def __init__(self, growth_rate, compression_factor=0.5, blocks=[6,12,24,16]):\n","        self.k = growth_rate\n","        self.compression = compression_factor\n","        self.model = self.make_model(blocks)\n","\n","    def dense_block(self, input_tensor, input_channels, nb_blocks):\n","        x = input_tensor\n","        n_channels = input_channels\n","        for i in range(nb_blocks):\n","            main = x\n","            x = BatchNormalization()(x)\n","            x = Activation(\"relu\")(x)\n","            x = Conv2D(128, (1, 1))(x)\n","            x = BatchNormalization()(x)\n","            x = Activation(\"relu\")(x)\n","            \n","            x = Conv2D(self.k, (3, 3), padding=\"same\")(x)\n","            x = Concatenate()([main, x])\n","            n_channels += self.k\n","        return x, n_channels\n","\n","    def transition_layer(self, input_tensor, input_channels):\n","        n_channels = int(input_channels * self.compression)\n","        \n","        x = Conv2D(n_channels, (1, 1))(input_tensor)\n","        x = AveragePooling2D((2, 2))(x)\n","        return x, n_channels\n","\n","    def make_model(self, blocks):\n","        input = Input(shape=(32,32,3))\n","        n = 16\n","        x = Conv2D(n, (1,1))(input)\n","        for i in range(len(blocks)):\n","            if i != 0:\n","                x, n = self.transition_layer(x, n)\n","            x, n = self.dense_block(x, n, blocks[i])\n","        x = GlobalAveragePooling2D()(x)\n","        output = Dense(10, activation=\"softmax\")(x)\n","        model = Model(input, output)\n","        return model\n","\n","    def train(self, X_train, y_train, X_val, y_val):\n","        self.model.compile(optimizer=Adam(), loss=\"categorical_crossentropy\", metrics=[\"acc\"])\n","        datagen = ImageDataGenerator(\n","            rescale=1./255,\n","            rotation_range=20,\n","            width_shift_range=0.2,\n","            height_shift_range=0.2,\n","            channel_shift_range=50,\n","            horizontal_flip=True)\n","        # history = self.model.fit(X_train, y_train, batch_size=128, epochs=1, validation_data=(X_val, y_val)).history\n","        history = self.model.fit_generator(datagen.flow(X_train, y_train, batch_size=128),\n","            steps_per_epoch=len(X_train) / 128, validation_data=(X_val, y_val), epochs=100).history\n","        with open(\"history.dat\", \"wb\") as fp:\n","            pickle.dump(history, fp)"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EI1KSRRiJj-Y","executionInfo":{"status":"ok","timestamp":1626600638892,"user_tz":-540,"elapsed":12270229,"user":{"displayName":"石居拓己","photoUrl":"","userId":"06001050725637052584"}},"outputId":"bf0a9548-09c2-4de1-cf37-ecdcbbd09f2f"},"source":["densenet = DenseNetSimple(16)\n","\n","(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n","X_test = (X_test / 255.0).astype(\"float32\")\n","y_train, y_test = to_categorical(y_train), to_categorical(y_test)\n","\n","densenet.train(X_train, y_train, X_test, y_test)"],"execution_count":26,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1915: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/100\n","390/390 [==============================] - 159s 341ms/step - loss: 2.2390 - acc: 0.2670 - val_loss: 1.6967 - val_acc: 0.3895\n","Epoch 2/100\n","390/390 [==============================] - 121s 309ms/step - loss: 1.4857 - acc: 0.4608 - val_loss: 1.7135 - val_acc: 0.4747\n","Epoch 3/100\n","390/390 [==============================] - 120s 308ms/step - loss: 1.1553 - acc: 0.5906 - val_loss: 1.6008 - val_acc: 0.5676\n","Epoch 4/100\n","390/390 [==============================] - 121s 309ms/step - loss: 0.9273 - acc: 0.6753 - val_loss: 1.4329 - val_acc: 0.6357\n","Epoch 5/100\n","390/390 [==============================] - 120s 308ms/step - loss: 0.7838 - acc: 0.7274 - val_loss: 0.9571 - val_acc: 0.6940\n","Epoch 6/100\n","390/390 [==============================] - 120s 308ms/step - loss: 0.6989 - acc: 0.7575 - val_loss: 0.7953 - val_acc: 0.7464\n","Epoch 7/100\n","390/390 [==============================] - 124s 317ms/step - loss: 0.6379 - acc: 0.7790 - val_loss: 0.6868 - val_acc: 0.7853\n","Epoch 8/100\n","390/390 [==============================] - 124s 316ms/step - loss: 0.5959 - acc: 0.7928 - val_loss: 1.0878 - val_acc: 0.6972\n","Epoch 9/100\n","390/390 [==============================] - 120s 308ms/step - loss: 0.5529 - acc: 0.8087 - val_loss: 0.7700 - val_acc: 0.7590\n","Epoch 10/100\n","390/390 [==============================] - 124s 316ms/step - loss: 0.5228 - acc: 0.8216 - val_loss: 0.6451 - val_acc: 0.7890\n","Epoch 11/100\n","390/390 [==============================] - 124s 316ms/step - loss: 0.4962 - acc: 0.8290 - val_loss: 0.9177 - val_acc: 0.7289\n","Epoch 12/100\n","390/390 [==============================] - 124s 317ms/step - loss: 0.4754 - acc: 0.8359 - val_loss: 0.8436 - val_acc: 0.7627\n","Epoch 13/100\n","390/390 [==============================] - 124s 316ms/step - loss: 0.4482 - acc: 0.8462 - val_loss: 0.5829 - val_acc: 0.8121\n","Epoch 14/100\n","390/390 [==============================] - 120s 308ms/step - loss: 0.4211 - acc: 0.8541 - val_loss: 0.6209 - val_acc: 0.8136\n","Epoch 15/100\n","390/390 [==============================] - 124s 317ms/step - loss: 0.4013 - acc: 0.8614 - val_loss: 0.4382 - val_acc: 0.8606\n","Epoch 16/100\n","390/390 [==============================] - 120s 308ms/step - loss: 0.3869 - acc: 0.8674 - val_loss: 0.5993 - val_acc: 0.8134\n","Epoch 17/100\n","390/390 [==============================] - 120s 308ms/step - loss: 0.3692 - acc: 0.8716 - val_loss: 0.5983 - val_acc: 0.8138\n","Epoch 18/100\n","390/390 [==============================] - 120s 307ms/step - loss: 0.3601 - acc: 0.8764 - val_loss: 0.6274 - val_acc: 0.8158\n","Epoch 19/100\n","390/390 [==============================] - 120s 307ms/step - loss: 0.3333 - acc: 0.8845 - val_loss: 0.6499 - val_acc: 0.8049\n","Epoch 20/100\n","390/390 [==============================] - 120s 307ms/step - loss: 0.3404 - acc: 0.8815 - val_loss: 0.6466 - val_acc: 0.8169\n","Epoch 21/100\n","390/390 [==============================] - 120s 307ms/step - loss: 0.3312 - acc: 0.8863 - val_loss: 0.4705 - val_acc: 0.8548\n","Epoch 22/100\n","390/390 [==============================] - 120s 308ms/step - loss: 0.3153 - acc: 0.8905 - val_loss: 0.6664 - val_acc: 0.8183\n","Epoch 23/100\n","390/390 [==============================] - 120s 307ms/step - loss: 0.2999 - acc: 0.8960 - val_loss: 0.6169 - val_acc: 0.8360\n","Epoch 24/100\n","390/390 [==============================] - 124s 317ms/step - loss: 0.2899 - acc: 0.9011 - val_loss: 0.5847 - val_acc: 0.8349\n","Epoch 25/100\n","390/390 [==============================] - 124s 317ms/step - loss: 0.2829 - acc: 0.9029 - val_loss: 0.3919 - val_acc: 0.8799\n","Epoch 26/100\n","390/390 [==============================] - 121s 308ms/step - loss: 0.2622 - acc: 0.9095 - val_loss: 0.3888 - val_acc: 0.8807\n","Epoch 27/100\n","390/390 [==============================] - 124s 317ms/step - loss: 0.2703 - acc: 0.9046 - val_loss: 0.4128 - val_acc: 0.8760\n","Epoch 28/100\n","390/390 [==============================] - 121s 308ms/step - loss: 0.2548 - acc: 0.9108 - val_loss: 0.4476 - val_acc: 0.8750\n","Epoch 29/100\n","390/390 [==============================] - 120s 308ms/step - loss: 0.2483 - acc: 0.9125 - val_loss: 0.4708 - val_acc: 0.8687\n","Epoch 30/100\n","390/390 [==============================] - 120s 308ms/step - loss: 0.2429 - acc: 0.9154 - val_loss: 0.4271 - val_acc: 0.8805\n","Epoch 31/100\n","390/390 [==============================] - 120s 308ms/step - loss: 0.2411 - acc: 0.9170 - val_loss: 0.3736 - val_acc: 0.8890\n","Epoch 32/100\n","390/390 [==============================] - 124s 317ms/step - loss: 0.2276 - acc: 0.9222 - val_loss: 0.6055 - val_acc: 0.8487\n","Epoch 33/100\n","390/390 [==============================] - 124s 317ms/step - loss: 0.2267 - acc: 0.9198 - val_loss: 0.3618 - val_acc: 0.8949\n","Epoch 34/100\n","390/390 [==============================] - 124s 317ms/step - loss: 0.2205 - acc: 0.9229 - val_loss: 0.5104 - val_acc: 0.8664\n","Epoch 35/100\n","390/390 [==============================] - 120s 307ms/step - loss: 0.2065 - acc: 0.9267 - val_loss: 0.5413 - val_acc: 0.8517\n","Epoch 36/100\n","390/390 [==============================] - 124s 317ms/step - loss: 0.2154 - acc: 0.9265 - val_loss: 0.4890 - val_acc: 0.8705\n","Epoch 37/100\n","390/390 [==============================] - 120s 308ms/step - loss: 0.2112 - acc: 0.9259 - val_loss: 0.7092 - val_acc: 0.8196\n","Epoch 38/100\n","390/390 [==============================] - 120s 307ms/step - loss: 0.1965 - acc: 0.9326 - val_loss: 0.5926 - val_acc: 0.8507\n","Epoch 39/100\n","390/390 [==============================] - 124s 317ms/step - loss: 0.1958 - acc: 0.9333 - val_loss: 0.4477 - val_acc: 0.8828\n","Epoch 40/100\n","390/390 [==============================] - 124s 316ms/step - loss: 0.1991 - acc: 0.9301 - val_loss: 0.4842 - val_acc: 0.8700\n","Epoch 41/100\n","390/390 [==============================] - 124s 316ms/step - loss: 0.1870 - acc: 0.9357 - val_loss: 0.4037 - val_acc: 0.8921\n","Epoch 42/100\n","390/390 [==============================] - 124s 317ms/step - loss: 0.1756 - acc: 0.9395 - val_loss: 0.3882 - val_acc: 0.8970\n","Epoch 43/100\n","390/390 [==============================] - 120s 308ms/step - loss: 0.1836 - acc: 0.9357 - val_loss: 0.4481 - val_acc: 0.8819\n","Epoch 44/100\n","390/390 [==============================] - 124s 317ms/step - loss: 0.1773 - acc: 0.9387 - val_loss: 0.4639 - val_acc: 0.8812\n","Epoch 45/100\n","390/390 [==============================] - 124s 317ms/step - loss: 0.1764 - acc: 0.9412 - val_loss: 0.4458 - val_acc: 0.8867\n","Epoch 46/100\n","390/390 [==============================] - 124s 317ms/step - loss: 0.1689 - acc: 0.9422 - val_loss: 0.4326 - val_acc: 0.8904\n","Epoch 47/100\n","390/390 [==============================] - 120s 308ms/step - loss: 0.1679 - acc: 0.9426 - val_loss: 0.3870 - val_acc: 0.8937\n","Epoch 48/100\n","390/390 [==============================] - 124s 317ms/step - loss: 0.1665 - acc: 0.9426 - val_loss: 0.3788 - val_acc: 0.8963\n","Epoch 49/100\n","390/390 [==============================] - 121s 308ms/step - loss: 0.1576 - acc: 0.9456 - val_loss: 0.4864 - val_acc: 0.8775\n","Epoch 50/100\n","390/390 [==============================] - 124s 317ms/step - loss: 0.1585 - acc: 0.9447 - val_loss: 0.5799 - val_acc: 0.8730\n","Epoch 51/100\n","390/390 [==============================] - 124s 317ms/step - loss: 0.1634 - acc: 0.9437 - val_loss: 0.4766 - val_acc: 0.8856\n","Epoch 52/100\n","390/390 [==============================] - 124s 317ms/step - loss: 0.1590 - acc: 0.9436 - val_loss: 0.4186 - val_acc: 0.8926\n","Epoch 53/100\n","390/390 [==============================] - 121s 310ms/step - loss: 0.1464 - acc: 0.9505 - val_loss: 0.4906 - val_acc: 0.8869\n","Epoch 54/100\n","390/390 [==============================] - 124s 318ms/step - loss: 0.1477 - acc: 0.9502 - val_loss: 0.4003 - val_acc: 0.8971\n","Epoch 55/100\n","390/390 [==============================] - 121s 308ms/step - loss: 0.1484 - acc: 0.9496 - val_loss: 0.4255 - val_acc: 0.8925\n","Epoch 56/100\n","390/390 [==============================] - 124s 317ms/step - loss: 0.1495 - acc: 0.9485 - val_loss: 0.4001 - val_acc: 0.8986\n","Epoch 57/100\n","390/390 [==============================] - 121s 310ms/step - loss: 0.1429 - acc: 0.9518 - val_loss: 0.4454 - val_acc: 0.8876\n","Epoch 58/100\n","390/390 [==============================] - 125s 319ms/step - loss: 0.1387 - acc: 0.9526 - val_loss: 0.4245 - val_acc: 0.8959\n","Epoch 59/100\n","390/390 [==============================] - 124s 317ms/step - loss: 0.1333 - acc: 0.9538 - val_loss: 0.4308 - val_acc: 0.8969\n","Epoch 60/100\n","390/390 [==============================] - 121s 310ms/step - loss: 0.1389 - acc: 0.9532 - val_loss: 0.4929 - val_acc: 0.8899\n","Epoch 61/100\n","390/390 [==============================] - 121s 309ms/step - loss: 0.1355 - acc: 0.9535 - val_loss: 0.4476 - val_acc: 0.9063\n","Epoch 62/100\n","390/390 [==============================] - 121s 308ms/step - loss: 0.1279 - acc: 0.9564 - val_loss: 0.5535 - val_acc: 0.8719\n","Epoch 63/100\n","390/390 [==============================] - 121s 310ms/step - loss: 0.1350 - acc: 0.9541 - val_loss: 0.3939 - val_acc: 0.9039\n","Epoch 64/100\n","390/390 [==============================] - 124s 318ms/step - loss: 0.1297 - acc: 0.9548 - val_loss: 0.4037 - val_acc: 0.9007\n","Epoch 65/100\n","390/390 [==============================] - 121s 309ms/step - loss: 0.1209 - acc: 0.9598 - val_loss: 0.3746 - val_acc: 0.9059\n","Epoch 66/100\n","390/390 [==============================] - 121s 310ms/step - loss: 0.1253 - acc: 0.9571 - val_loss: 0.3500 - val_acc: 0.9120\n","Epoch 67/100\n","390/390 [==============================] - 120s 308ms/step - loss: 0.1218 - acc: 0.9581 - val_loss: 0.4192 - val_acc: 0.9041\n","Epoch 68/100\n","390/390 [==============================] - 124s 318ms/step - loss: 0.1164 - acc: 0.9609 - val_loss: 0.6610 - val_acc: 0.8670\n","Epoch 69/100\n","390/390 [==============================] - 121s 309ms/step - loss: 0.1165 - acc: 0.9606 - val_loss: 0.5134 - val_acc: 0.8915\n","Epoch 70/100\n","390/390 [==============================] - 120s 308ms/step - loss: 0.1179 - acc: 0.9595 - val_loss: 0.5149 - val_acc: 0.8952\n","Epoch 71/100\n","390/390 [==============================] - 120s 307ms/step - loss: 0.1140 - acc: 0.9611 - val_loss: 0.4227 - val_acc: 0.9014\n","Epoch 72/100\n","390/390 [==============================] - 120s 307ms/step - loss: 0.1216 - acc: 0.9582 - val_loss: 0.5266 - val_acc: 0.8909\n","Epoch 73/100\n","390/390 [==============================] - 120s 307ms/step - loss: 0.1059 - acc: 0.9643 - val_loss: 0.4496 - val_acc: 0.9038\n","Epoch 74/100\n","390/390 [==============================] - 123s 316ms/step - loss: 0.1136 - acc: 0.9617 - val_loss: 0.6376 - val_acc: 0.8737\n","Epoch 75/100\n","390/390 [==============================] - 123s 316ms/step - loss: 0.1095 - acc: 0.9627 - val_loss: 0.5946 - val_acc: 0.8773\n","Epoch 76/100\n","390/390 [==============================] - 124s 316ms/step - loss: 0.1088 - acc: 0.9633 - val_loss: 0.4375 - val_acc: 0.9009\n","Epoch 77/100\n","390/390 [==============================] - 124s 316ms/step - loss: 0.1159 - acc: 0.9618 - val_loss: 0.4396 - val_acc: 0.9042\n","Epoch 78/100\n","390/390 [==============================] - 120s 307ms/step - loss: 0.1124 - acc: 0.9625 - val_loss: 0.5715 - val_acc: 0.8890\n","Epoch 79/100\n","390/390 [==============================] - 120s 307ms/step - loss: 0.0986 - acc: 0.9663 - val_loss: 0.5929 - val_acc: 0.8844\n","Epoch 80/100\n","390/390 [==============================] - 120s 308ms/step - loss: 0.1080 - acc: 0.9642 - val_loss: 0.6104 - val_acc: 0.8865\n","Epoch 81/100\n","390/390 [==============================] - 124s 317ms/step - loss: 0.1055 - acc: 0.9647 - val_loss: 0.5609 - val_acc: 0.8876\n","Epoch 82/100\n","390/390 [==============================] - 124s 317ms/step - loss: 0.1031 - acc: 0.9643 - val_loss: 0.4758 - val_acc: 0.9028\n","Epoch 83/100\n","390/390 [==============================] - 124s 318ms/step - loss: 0.1119 - acc: 0.9630 - val_loss: 0.5654 - val_acc: 0.8912\n","Epoch 84/100\n","390/390 [==============================] - 121s 311ms/step - loss: 0.0999 - acc: 0.9658 - val_loss: 0.6844 - val_acc: 0.8770\n","Epoch 85/100\n","390/390 [==============================] - 124s 317ms/step - loss: 0.1002 - acc: 0.9661 - val_loss: 0.5297 - val_acc: 0.9012\n","Epoch 86/100\n","390/390 [==============================] - 120s 308ms/step - loss: 0.0983 - acc: 0.9669 - val_loss: 0.4244 - val_acc: 0.9171\n","Epoch 87/100\n","390/390 [==============================] - 121s 309ms/step - loss: 0.0953 - acc: 0.9683 - val_loss: 0.5073 - val_acc: 0.9027\n","Epoch 88/100\n","390/390 [==============================] - 124s 317ms/step - loss: 0.0984 - acc: 0.9659 - val_loss: 0.5477 - val_acc: 0.8941\n","Epoch 89/100\n","390/390 [==============================] - 124s 317ms/step - loss: 0.0990 - acc: 0.9656 - val_loss: 0.5648 - val_acc: 0.8925\n","Epoch 90/100\n","390/390 [==============================] - 124s 317ms/step - loss: 0.0931 - acc: 0.9688 - val_loss: 0.5097 - val_acc: 0.9021\n","Epoch 91/100\n","390/390 [==============================] - 120s 308ms/step - loss: 0.0914 - acc: 0.9694 - val_loss: 0.4602 - val_acc: 0.9069\n","Epoch 92/100\n","390/390 [==============================] - 124s 317ms/step - loss: 0.0943 - acc: 0.9678 - val_loss: 0.4839 - val_acc: 0.9018\n","Epoch 93/100\n","390/390 [==============================] - 124s 317ms/step - loss: 0.0965 - acc: 0.9679 - val_loss: 0.5394 - val_acc: 0.8903\n","Epoch 94/100\n","390/390 [==============================] - 120s 307ms/step - loss: 0.0951 - acc: 0.9687 - val_loss: 0.4721 - val_acc: 0.9100\n","Epoch 95/100\n","390/390 [==============================] - 124s 316ms/step - loss: 0.0914 - acc: 0.9683 - val_loss: 0.5583 - val_acc: 0.8960\n","Epoch 96/100\n","390/390 [==============================] - 120s 307ms/step - loss: 0.0914 - acc: 0.9694 - val_loss: 0.4817 - val_acc: 0.9050\n","Epoch 97/100\n","390/390 [==============================] - 120s 308ms/step - loss: 0.0888 - acc: 0.9717 - val_loss: 0.4886 - val_acc: 0.9100\n","Epoch 98/100\n","390/390 [==============================] - 124s 317ms/step - loss: 0.0913 - acc: 0.9695 - val_loss: 0.3968 - val_acc: 0.9165\n","Epoch 99/100\n","390/390 [==============================] - 124s 316ms/step - loss: 0.0898 - acc: 0.9692 - val_loss: 0.5423 - val_acc: 0.8997\n","Epoch 100/100\n","390/390 [==============================] - 124s 316ms/step - loss: 0.0879 - acc: 0.9711 - val_loss: 0.4437 - val_acc: 0.9095\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Pts87V7DJkFN","executionInfo":{"status":"ok","timestamp":1626600641797,"user_tz":-540,"elapsed":5,"user":{"displayName":"石居拓己","photoUrl":"","userId":"06001050725637052584"}}},"source":["with open(\"history.dat\", \"rb\") as fp:\n","    history = pickle.load(fp)"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"FOvsC1CJJkL4","executionInfo":{"status":"ok","timestamp":1626600640741,"user_tz":-540,"elapsed":3,"user":{"displayName":"石居拓己","photoUrl":"","userId":"06001050725637052584"}}},"source":["import matplotlib.pyplot as plt"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":283},"id":"iK3ERWQiVQ22","executionInfo":{"status":"ok","timestamp":1626600641798,"user_tz":-540,"elapsed":5,"user":{"displayName":"石居拓己","photoUrl":"","userId":"06001050725637052584"}},"outputId":"14172743-cb42-4876-cf5b-352908d2804e"},"source":["plt.plot(range(1,101), history[\"acc\"], label = \"training\")\n","plt.plot(range(1,101), history[\"val_acc\"], label = \"validation\")\n","plt.xlabel(\"Epochs\")\n","plt.ylabel(\"Accuracy\")\n","plt.legend()\n","plt.show()"],"execution_count":29,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"izMiDA3S44rG"},"source":["## Transformer"]},{"cell_type":"markdown","metadata":{"id":"SyIZ3Aryfw5J"},"source":["- seq2seqとは\n","系列を入力にして、系列を出力する。  \n","Encoder-Decoderモデルとも呼ばれる。  \n","- 言語処理とRNN  \n","文章は時系列情報が重要になるのでRNNに適する。適切に構築したモデルを用いれば、次にくる単語として自然なものを予想することができる。  \n","次の単語が予想できるのであれば、最初の単語から文章を作っていくこともできる。  \n","これがEncoder-Decoderモデル。  \n"]},{"cell_type":"markdown","metadata":{"id":"kRVFZKxt6WJQ"},"source":["以下Seq2Seqの例を見る。"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yau47PWkrceJ","executionInfo":{"status":"ok","timestamp":1626620680024,"user_tz":-540,"elapsed":2887,"user":{"displayName":"石居拓己","photoUrl":"","userId":"06001050725637052584"}},"outputId":"c7d17704-caed-4626-941d-009830b5ab74"},"source":["!pip install pip"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (19.3.1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6xrs999Ahp4D","executionInfo":{"status":"ok","timestamp":1626620687789,"user_tz":-540,"elapsed":7770,"user":{"displayName":"石居拓己","photoUrl":"","userId":"06001050725637052584"}},"outputId":"c72d65c5-9344-42ba-9ee0-4e1bcda2ba1c"},"source":["from os import path\n","\n","!pip install pytorch\n","import torch"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Collecting pytorch\n","  Downloading https://files.pythonhosted.org/packages/ee/67/f403d4ae6e9cd74b546ee88cccdb29b8415a9c1b3d80aebeb20c9ea91d96/pytorch-1.0.2.tar.gz\n","Building wheels for collected packages: pytorch\n","  Building wheel for pytorch (setup.py) ... \u001b[?25lerror\n","\u001b[31m  ERROR: Failed building wheel for pytorch\u001b[0m\n","\u001b[?25h  Running setup.py clean for pytorch\n","Failed to build pytorch\n","Installing collected packages: pytorch\n","    Running setup.py install for pytorch ... \u001b[?25l\u001b[?25herror\n","\u001b[31mERROR: Command errored out with exit status 1: /usr/bin/python3 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-mrudwsb_/pytorch/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-mrudwsb_/pytorch/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-zwzs5kp0/install-record.txt --single-version-externally-managed --compile Check the logs for full command output.\u001b[0m\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZiI1d6XxrOZx","executionInfo":{"status":"ok","timestamp":1626620695507,"user_tz":-540,"elapsed":7727,"user":{"displayName":"石居拓己","photoUrl":"","userId":"06001050725637052584"}},"outputId":"ddbe3b37-73f2-43ee-9257-5e91f59a73ce"},"source":["! wget https://www.dropbox.com/s/9narw5x4uizmehh/utils.py\n","! mkdir images data\n","\n","# data取得\n","! wget https://www.dropbox.com/s/o4kyc52a8we25wy/dev.en -P data/\n","! wget https://www.dropbox.com/s/kdgskm5hzg6znuc/dev.ja -P data/\n","! wget https://www.dropbox.com/s/gyyx4gohv9v65uh/test.en -P data/\n","! wget https://www.dropbox.com/s/hotxwbgoe2n013k/test.ja -P data/\n","! wget https://www.dropbox.com/s/5lsftkmb20ay9e1/train.en -P data/\n","! wget https://www.dropbox.com/s/ak53qirssci6f1j/train.ja -P data/"],"execution_count":3,"outputs":[{"output_type":"stream","text":["--2021-07-18 15:04:47--  https://www.dropbox.com/s/9narw5x4uizmehh/utils.py\n","Resolving www.dropbox.com (www.dropbox.com)... 162.125.4.18, 2620:100:6017:18::a27d:212\n","Connecting to www.dropbox.com (www.dropbox.com)|162.125.4.18|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: /s/raw/9narw5x4uizmehh/utils.py [following]\n","--2021-07-18 15:04:47--  https://www.dropbox.com/s/raw/9narw5x4uizmehh/utils.py\n","Reusing existing connection to www.dropbox.com:443.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://ucbb722dfa955f3495f0987ce40f.dl.dropboxusercontent.com/cd/0/inline/BSjJ2_r8IhLeaLdGc3e7rz4pSNx4GPVg7AOLVdclLAVYIpBU7lETsQuiHShhyc1qvDLbgP9HAF5uBw1Ef-jReSydygvvCava4j_lw74fgn8u_Tq06Oe6II4QyVgXh9vKon-2FKIa3majbCxEnbBaZkX4/file# [following]\n","--2021-07-18 15:04:48--  https://ucbb722dfa955f3495f0987ce40f.dl.dropboxusercontent.com/cd/0/inline/BSjJ2_r8IhLeaLdGc3e7rz4pSNx4GPVg7AOLVdclLAVYIpBU7lETsQuiHShhyc1qvDLbgP9HAF5uBw1Ef-jReSydygvvCava4j_lw74fgn8u_Tq06Oe6II4QyVgXh9vKon-2FKIa3majbCxEnbBaZkX4/file\n","Resolving ucbb722dfa955f3495f0987ce40f.dl.dropboxusercontent.com (ucbb722dfa955f3495f0987ce40f.dl.dropboxusercontent.com)... 162.125.2.15, 2620:100:6017:15::a27d:20f\n","Connecting to ucbb722dfa955f3495f0987ce40f.dl.dropboxusercontent.com (ucbb722dfa955f3495f0987ce40f.dl.dropboxusercontent.com)|162.125.2.15|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 949 [text/plain]\n","Saving to: ‘utils.py’\n","\n","utils.py            100%[===================>]     949  --.-KB/s    in 0s      \n","\n","2021-07-18 15:04:48 (168 MB/s) - ‘utils.py’ saved [949/949]\n","\n","--2021-07-18 15:04:48--  https://www.dropbox.com/s/o4kyc52a8we25wy/dev.en\n","Resolving www.dropbox.com (www.dropbox.com)... 162.125.4.18, 2620:100:6017:18::a27d:212\n","Connecting to www.dropbox.com (www.dropbox.com)|162.125.4.18|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: /s/raw/o4kyc52a8we25wy/dev.en [following]\n","--2021-07-18 15:04:49--  https://www.dropbox.com/s/raw/o4kyc52a8we25wy/dev.en\n","Reusing existing connection to www.dropbox.com:443.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://uce5155013071b06270f702dcdd6.dl.dropboxusercontent.com/cd/0/inline/BSj97TNtH5QsQtyFARnxgFXqMxbMUv_QJnkSqGngjYGpCZFKEYhjNz2T5jiTfP9WjR4YK0ZCJTFbY-T7zk6GnVP7jBkOGd9bKPxJ0m4cZWq4CQV4tVAGfPKmksYQfRJyfitWOkD_XiUwWgFFP9zEnodc/file# [following]\n","--2021-07-18 15:04:49--  https://uce5155013071b06270f702dcdd6.dl.dropboxusercontent.com/cd/0/inline/BSj97TNtH5QsQtyFARnxgFXqMxbMUv_QJnkSqGngjYGpCZFKEYhjNz2T5jiTfP9WjR4YK0ZCJTFbY-T7zk6GnVP7jBkOGd9bKPxJ0m4cZWq4CQV4tVAGfPKmksYQfRJyfitWOkD_XiUwWgFFP9zEnodc/file\n","Resolving uce5155013071b06270f702dcdd6.dl.dropboxusercontent.com (uce5155013071b06270f702dcdd6.dl.dropboxusercontent.com)... 162.125.2.15, 2620:100:6017:15::a27d:20f\n","Connecting to uce5155013071b06270f702dcdd6.dl.dropboxusercontent.com (uce5155013071b06270f702dcdd6.dl.dropboxusercontent.com)|162.125.2.15|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 17054 (17K) [text/plain]\n","Saving to: ‘data/dev.en’\n","\n","dev.en              100%[===================>]  16.65K  --.-KB/s    in 0.001s  \n","\n","2021-07-18 15:04:49 (12.1 MB/s) - ‘data/dev.en’ saved [17054/17054]\n","\n","--2021-07-18 15:04:49--  https://www.dropbox.com/s/kdgskm5hzg6znuc/dev.ja\n","Resolving www.dropbox.com (www.dropbox.com)... 162.125.4.18, 2620:100:6017:18::a27d:212\n","Connecting to www.dropbox.com (www.dropbox.com)|162.125.4.18|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: /s/raw/kdgskm5hzg6znuc/dev.ja [following]\n","--2021-07-18 15:04:50--  https://www.dropbox.com/s/raw/kdgskm5hzg6znuc/dev.ja\n","Reusing existing connection to www.dropbox.com:443.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://uc5ae06c5b9060bdc32835309db2.dl.dropboxusercontent.com/cd/0/inline/BShUa-m_DTZSZ6EPThrw1q8Zz8DYwEzES_646ZrKBi7t1dLGP40KuciJj_0nLjk3v-sJ1c7vmz2LwWJOhz3h0enUYUE_2Ty9va25m8kX1WvNVNML4KjxnWkEay0cLUU2vGSRH7DDUNL28uGyqMJiXWQU/file# [following]\n","--2021-07-18 15:04:50--  https://uc5ae06c5b9060bdc32835309db2.dl.dropboxusercontent.com/cd/0/inline/BShUa-m_DTZSZ6EPThrw1q8Zz8DYwEzES_646ZrKBi7t1dLGP40KuciJj_0nLjk3v-sJ1c7vmz2LwWJOhz3h0enUYUE_2Ty9va25m8kX1WvNVNML4KjxnWkEay0cLUU2vGSRH7DDUNL28uGyqMJiXWQU/file\n","Resolving uc5ae06c5b9060bdc32835309db2.dl.dropboxusercontent.com (uc5ae06c5b9060bdc32835309db2.dl.dropboxusercontent.com)... 162.125.4.15, 2620:100:6022:15::a27d:420f\n","Connecting to uc5ae06c5b9060bdc32835309db2.dl.dropboxusercontent.com (uc5ae06c5b9060bdc32835309db2.dl.dropboxusercontent.com)|162.125.4.15|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 27781 (27K) [text/plain]\n","Saving to: ‘data/dev.ja’\n","\n","dev.ja              100%[===================>]  27.13K  --.-KB/s    in 0.06s   \n","\n","2021-07-18 15:04:51 (421 KB/s) - ‘data/dev.ja’ saved [27781/27781]\n","\n","--2021-07-18 15:04:51--  https://www.dropbox.com/s/gyyx4gohv9v65uh/test.en\n","Resolving www.dropbox.com (www.dropbox.com)... 162.125.4.18, 2620:100:6017:18::a27d:212\n","Connecting to www.dropbox.com (www.dropbox.com)|162.125.4.18|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: /s/raw/gyyx4gohv9v65uh/test.en [following]\n","--2021-07-18 15:04:51--  https://www.dropbox.com/s/raw/gyyx4gohv9v65uh/test.en\n","Reusing existing connection to www.dropbox.com:443.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://uc5605ed163f8243af94d7848686.dl.dropboxusercontent.com/cd/0/inline/BSi_82bU66uwdGBwAhoLHxWC3KDCZGwO-iAPt1VcOGYN3NkgQZ6p0MQH0Ba-qmZuxviLTa46Xd0JlN8Xa7H5mNakVnm3JJmwpv3sD71xyZY9mFoznNX153J1Ev4MpCJvU7vdyhgSEHtk2IrANqxhkr03/file# [following]\n","--2021-07-18 15:04:52--  https://uc5605ed163f8243af94d7848686.dl.dropboxusercontent.com/cd/0/inline/BSi_82bU66uwdGBwAhoLHxWC3KDCZGwO-iAPt1VcOGYN3NkgQZ6p0MQH0Ba-qmZuxviLTa46Xd0JlN8Xa7H5mNakVnm3JJmwpv3sD71xyZY9mFoznNX153J1Ev4MpCJvU7vdyhgSEHtk2IrANqxhkr03/file\n","Resolving uc5605ed163f8243af94d7848686.dl.dropboxusercontent.com (uc5605ed163f8243af94d7848686.dl.dropboxusercontent.com)... 162.125.2.15, 2620:100:6017:15::a27d:20f\n","Connecting to uc5605ed163f8243af94d7848686.dl.dropboxusercontent.com (uc5605ed163f8243af94d7848686.dl.dropboxusercontent.com)|162.125.2.15|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 17301 (17K) [text/plain]\n","Saving to: ‘data/test.en’\n","\n","test.en             100%[===================>]  16.90K  --.-KB/s    in 0.001s  \n","\n","2021-07-18 15:04:52 (13.1 MB/s) - ‘data/test.en’ saved [17301/17301]\n","\n","--2021-07-18 15:04:52--  https://www.dropbox.com/s/hotxwbgoe2n013k/test.ja\n","Resolving www.dropbox.com (www.dropbox.com)... 162.125.2.18, 2620:100:6017:18::a27d:212\n","Connecting to www.dropbox.com (www.dropbox.com)|162.125.2.18|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: /s/raw/hotxwbgoe2n013k/test.ja [following]\n","--2021-07-18 15:04:52--  https://www.dropbox.com/s/raw/hotxwbgoe2n013k/test.ja\n","Reusing existing connection to www.dropbox.com:443.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://ucb0ab422b1013b810e29fa43b4d.dl.dropboxusercontent.com/cd/0/inline/BSjz6lU8aOhxS1ILJVHmEaBkpruQ5C1li5FomvEiG4PhRJWDl89Obh1u52j7q7MPNe3b9yVp8ku1_49VYtkJNTE4-QCQ3AVFYy3n2LhG8wHW9j0iX3c0RRl0DN7MjY4exGXEBGKlQkSNwS06ZoDxxK2A/file# [following]\n","--2021-07-18 15:04:52--  https://ucb0ab422b1013b810e29fa43b4d.dl.dropboxusercontent.com/cd/0/inline/BSjz6lU8aOhxS1ILJVHmEaBkpruQ5C1li5FomvEiG4PhRJWDl89Obh1u52j7q7MPNe3b9yVp8ku1_49VYtkJNTE4-QCQ3AVFYy3n2LhG8wHW9j0iX3c0RRl0DN7MjY4exGXEBGKlQkSNwS06ZoDxxK2A/file\n","Resolving ucb0ab422b1013b810e29fa43b4d.dl.dropboxusercontent.com (ucb0ab422b1013b810e29fa43b4d.dl.dropboxusercontent.com)... 162.125.2.15, 2620:100:6022:15::a27d:420f\n","Connecting to ucb0ab422b1013b810e29fa43b4d.dl.dropboxusercontent.com (ucb0ab422b1013b810e29fa43b4d.dl.dropboxusercontent.com)|162.125.2.15|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 27793 (27K) [text/plain]\n","Saving to: ‘data/test.ja’\n","\n","test.ja             100%[===================>]  27.14K  --.-KB/s    in 0.03s   \n","\n","2021-07-18 15:04:53 (949 KB/s) - ‘data/test.ja’ saved [27793/27793]\n","\n","--2021-07-18 15:04:53--  https://www.dropbox.com/s/5lsftkmb20ay9e1/train.en\n","Resolving www.dropbox.com (www.dropbox.com)... 162.125.2.18, 2620:100:6017:18::a27d:212\n","Connecting to www.dropbox.com (www.dropbox.com)|162.125.2.18|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: /s/raw/5lsftkmb20ay9e1/train.en [following]\n","--2021-07-18 15:04:53--  https://www.dropbox.com/s/raw/5lsftkmb20ay9e1/train.en\n","Reusing existing connection to www.dropbox.com:443.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://uc20ee722bbf6969d943a79908c5.dl.dropboxusercontent.com/cd/0/inline/BSgBgku8w2_-O15EWaYzIGavzdp0uwcMTpjGG5tptQnUn7SM_qXYjEDKsH1b0mLZdu-pmYlU9iNTTCSgCn6CL7KvA5k_lAXQMGcT_C2BTGHNJeDlPEfmeQ0k3l6o38yei9A581tZ87y19Ibf0eVEXRbc/file# [following]\n","--2021-07-18 15:04:53--  https://uc20ee722bbf6969d943a79908c5.dl.dropboxusercontent.com/cd/0/inline/BSgBgku8w2_-O15EWaYzIGavzdp0uwcMTpjGG5tptQnUn7SM_qXYjEDKsH1b0mLZdu-pmYlU9iNTTCSgCn6CL7KvA5k_lAXQMGcT_C2BTGHNJeDlPEfmeQ0k3l6o38yei9A581tZ87y19Ibf0eVEXRbc/file\n","Resolving uc20ee722bbf6969d943a79908c5.dl.dropboxusercontent.com (uc20ee722bbf6969d943a79908c5.dl.dropboxusercontent.com)... 162.125.2.15, 2620:100:6022:15::a27d:420f\n","Connecting to uc20ee722bbf6969d943a79908c5.dl.dropboxusercontent.com (uc20ee722bbf6969d943a79908c5.dl.dropboxusercontent.com)|162.125.2.15|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1701356 (1.6M) [text/plain]\n","Saving to: ‘data/train.en’\n","\n","train.en            100%[===================>]   1.62M  10.6MB/s    in 0.2s    \n","\n","2021-07-18 15:04:54 (10.6 MB/s) - ‘data/train.en’ saved [1701356/1701356]\n","\n","--2021-07-18 15:04:54--  https://www.dropbox.com/s/ak53qirssci6f1j/train.ja\n","Resolving www.dropbox.com (www.dropbox.com)... 162.125.2.18, 2620:100:6017:18::a27d:212\n","Connecting to www.dropbox.com (www.dropbox.com)|162.125.2.18|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: /s/raw/ak53qirssci6f1j/train.ja [following]\n","--2021-07-18 15:04:54--  https://www.dropbox.com/s/raw/ak53qirssci6f1j/train.ja\n","Reusing existing connection to www.dropbox.com:443.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://uc0d06253e575dbb460593453e27.dl.dropboxusercontent.com/cd/0/inline/BSjxULutfL2eJ2kdvPFd9ePQyK1qKCy-CN4txxLJtEVxe4u6K72s0EaIvelOdd_7hk5jjfiJC4h4wJw6MTdGn24PyVe2gzHINLGxx3C_NGILeP3vjUEMvtfcXQF2De_sztPYSDI1akJFYoYuX-VGrszX/file# [following]\n","--2021-07-18 15:04:54--  https://uc0d06253e575dbb460593453e27.dl.dropboxusercontent.com/cd/0/inline/BSjxULutfL2eJ2kdvPFd9ePQyK1qKCy-CN4txxLJtEVxe4u6K72s0EaIvelOdd_7hk5jjfiJC4h4wJw6MTdGn24PyVe2gzHINLGxx3C_NGILeP3vjUEMvtfcXQF2De_sztPYSDI1akJFYoYuX-VGrszX/file\n","Resolving uc0d06253e575dbb460593453e27.dl.dropboxusercontent.com (uc0d06253e575dbb460593453e27.dl.dropboxusercontent.com)... 162.125.2.15, 2620:100:6022:15::a27d:420f\n","Connecting to uc0d06253e575dbb460593453e27.dl.dropboxusercontent.com (uc0d06253e575dbb460593453e27.dl.dropboxusercontent.com)|162.125.2.15|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 2784447 (2.7M) [text/plain]\n","Saving to: ‘data/train.ja’\n","\n","train.ja            100%[===================>]   2.66M  11.5MB/s    in 0.2s    \n","\n","2021-07-18 15:04:55 (11.5 MB/s) - ‘data/train.ja’ saved [2784447/2784447]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Yty2XGats4Ry","executionInfo":{"status":"ok","timestamp":1626620696351,"user_tz":-540,"elapsed":853,"user":{"displayName":"石居拓己","photoUrl":"","userId":"06001050725637052584"}},"outputId":"25c0be2e-9d9b-47a0-a528-90b506a9772d"},"source":["! head -10 data/train.en"],"execution_count":4,"outputs":[{"output_type":"stream","text":["i can 't tell who will arrive first .\n","many animals have been destroyed by men .\n","i 'm in the tennis club .\n","emi looks happy .\n","please bear this fact in mind .\n","she takes care of my children .\n","we want to be international .\n","you ought not to break your promise .\n","when you cross the street , watch out for cars .\n","i have nothing to live for .\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OrFvYMx9tLUP","executionInfo":{"status":"ok","timestamp":1626620697034,"user_tz":-540,"elapsed":685,"user":{"displayName":"石居拓己","photoUrl":"","userId":"06001050725637052584"}}},"source":["import random\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.utils import shuffle\n","from nltk import bleu_score\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.nn.utils.rnn import pad_packed_sequence, pack_padded_sequence\n","from utils import Vocab\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","torch.manual_seed(1)\n","random_state = 42"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"wOfQ9nRytOeK","executionInfo":{"status":"ok","timestamp":1626620697034,"user_tz":-540,"elapsed":3,"user":{"displayName":"石居拓己","photoUrl":"","userId":"06001050725637052584"}}},"source":["def load_data(file_path):\n","    data = []\n","    for line in open(file_path, encoding='utf-8'):\n","        words = line.strip().split()  \n","        data.append(words)\n","    return data"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"x1x9EX8KtVRg","executionInfo":{"status":"ok","timestamp":1626620697035,"user_tz":-540,"elapsed":3,"user":{"displayName":"石居拓己","photoUrl":"","userId":"06001050725637052584"}}},"source":["train_X = load_data('./data/train.en')\n","train_Y = load_data('./data/train.ja')\n","\n","train_X, valid_X, train_Y, valid_Y = train_test_split(train_X, train_Y, test_size=0.2, random_state=random_state)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"EWLmV9qctW-B","executionInfo":{"status":"ok","timestamp":1626620697263,"user_tz":-540,"elapsed":231,"user":{"displayName":"石居拓己","photoUrl":"","userId":"06001050725637052584"}}},"source":["PAD_TOKEN = \"<PAD>\"\n","BOS_TOKEN = \"<S>\"\n","EOS_TOKEN = \"</S>\"\n","UNK_TOKEN = \"<UNK>\"\n","PAD = 0\n","BOS = 1\n","EOS = 2\n","UNK = 3\n","\n","MIN_COUNT = 2\n","\n","word2id = {\n","    PAD_TOKEN: PAD,\n","    BOS_TOKEN: BOS,\n","    EOS_TOKEN: EOS,\n","    UNK_TOKEN: UNK,\n","}\n","\n","vocab_X = Vocab(word2id=word2id)\n","vocab_Y = Vocab(word2id=word2id)\n","vocab_X.build_vocab(train_X, min_count=MIN_COUNT)\n","vocab_Y.build_vocab(train_Y, min_count=MIN_COUNT)\n","\n","vocab_size_X = len(vocab_X.id2word)\n","vocab_size_Y = len(vocab_Y.id2word)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"LZ-VRZyRGa_3","executionInfo":{"status":"ok","timestamp":1626620698080,"user_tz":-540,"elapsed":818,"user":{"displayName":"石居拓己","photoUrl":"","userId":"06001050725637052584"}}},"source":["def sentence_to_ids(vocab, sentence):\n","    ids = [vocab.word2id.get(word, UNK) for word in sentence]\n","    ids += [EOS]  \n","    return ids"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"Jk0RjjYfGbCv","executionInfo":{"status":"ok","timestamp":1626620698081,"user_tz":-540,"elapsed":7,"user":{"displayName":"石居拓己","photoUrl":"","userId":"06001050725637052584"}}},"source":["train_X = [sentence_to_ids(vocab_X, sentence) for sentence in train_X]\n","train_Y = [sentence_to_ids(vocab_Y, sentence) for sentence in train_Y]\n","valid_X = [sentence_to_ids(vocab_X, sentence) for sentence in valid_X]\n","valid_Y = [sentence_to_ids(vocab_Y, sentence) for sentence in valid_Y]"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"vJr9lm1-tXAc","executionInfo":{"status":"ok","timestamp":1626620698081,"user_tz":-540,"elapsed":7,"user":{"displayName":"石居拓己","photoUrl":"","userId":"06001050725637052584"}}},"source":["def pad_seq(seq, max_length):\n","    res = seq + [PAD for i in range(max_length - len(seq))]\n","    return res"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"2IABGNsgtXKu","executionInfo":{"status":"ok","timestamp":1626620698081,"user_tz":-540,"elapsed":6,"user":{"displayName":"石居拓己","photoUrl":"","userId":"06001050725637052584"}}},"source":["class DataLoader(object):\n","\n","    def __init__(self, X, Y, batch_size, shuffle=False):\n","        self.data = list(zip(X, Y))\n","        self.batch_size = batch_size\n","        self.shuffle = shuffle\n","        self.start_index = 0\n","        \n","        self.reset()\n","    \n","    def reset(self):\n","        if self.shuffle: \n","            self.data = shuffle(self.data, random_state=random_state)\n","        self.start_index = 0  \n","    \n","    def __iter__(self):\n","        return self\n","\n","    def __next__(self):\n","        if self.start_index >= len(self.data):\n","            self.reset()\n","            raise StopIteration()\n","\n","        seqs_X, seqs_Y = zip(*self.data[self.start_index:self.start_index+self.batch_size])\n","        \n","        seq_pairs = sorted(zip(seqs_X, seqs_Y), key=lambda p: len(p[0]), reverse=True)\n","        seqs_X, seqs_Y = zip(*seq_pairs)\n","        \n","        lengths_X = [len(s) for s in seqs_X]\n","        lengths_Y = [len(s) for s in seqs_Y]\n","        max_length_X = max(lengths_X)\n","        max_length_Y = max(lengths_Y)\n","        padded_X = [pad_seq(s, max_length_X) for s in seqs_X]\n","        padded_Y = [pad_seq(s, max_length_Y) for s in seqs_Y]\n","        \n","        batch_X = torch.tensor(padded_X, dtype=torch.long, device=device).transpose(0, 1)\n","        batch_Y = torch.tensor(padded_Y, dtype=torch.long, device=device).transpose(0, 1)\n","\n","        self.start_index += self.batch_size\n","        return batch_X, batch_Y, lengths_X"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"70weH20dYYAa","executionInfo":{"status":"ok","timestamp":1626620698082,"user_tz":-540,"elapsed":7,"user":{"displayName":"石居拓己","photoUrl":"","userId":"06001050725637052584"}}},"source":["class Encoder(nn.Module):\n","    def __init__(self, input_size, hidden_size):\n","        super(Encoder, self).__init__()\n","        self.hidden_size = hidden_size\n","\n","        self.embedding = nn.Embedding(input_size, hidden_size, padding_idx=PAD)\n","        self.gru = nn.GRU(hidden_size, hidden_size)\n","\n","    def forward(self, seqs, input_lengths, hidden=None):\n","        emb = self.embedding(seqs)\n","        packed = pack_padded_sequence(emb, input_lengths)\n","        output, hidden = self.gru(packed, hidden)\n","        output, _ = pad_packed_sequence(output)\n","        return output, hidden"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"M_vzGwCgYYGT","executionInfo":{"status":"ok","timestamp":1626620698082,"user_tz":-540,"elapsed":7,"user":{"displayName":"石居拓己","photoUrl":"","userId":"06001050725637052584"}}},"source":["class Decoder(nn.Module):\n","    def __init__(self, hidden_size, output_size):\n","        super(Decoder, self).__init__()\n","        self.hidden_size = hidden_size\n","        self.output_size = output_size\n","\n","        self.embedding = nn.Embedding(output_size, hidden_size, padding_idx=PAD)\n","        self.gru = nn.GRU(hidden_size, hidden_size)\n","        self.out = nn.Linear(hidden_size, output_size)\n","\n","    def forward(self, seqs, hidden):\n","        emb = self.embedding(seqs)\n","        output, hidden = self.gru(emb, hidden)\n","        output = self.out(output)\n","        return output, hidden"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"V_xS5YFGYYNF","executionInfo":{"status":"ok","timestamp":1626620698082,"user_tz":-540,"elapsed":6,"user":{"displayName":"石居拓己","photoUrl":"","userId":"06001050725637052584"}}},"source":["class EncoderDecoder(nn.Module):\n","    def __init__(self, input_size, output_size, hidden_size):\n","        super(EncoderDecoder, self).__init__()\n","        self.encoder = Encoder(input_size, hidden_size)\n","        self.decoder = Decoder(hidden_size, output_size)\n","\n","    def forward(self, batch_X, lengths_X, max_length, batch_Y=None, use_teacher_forcing=False):\n","        _, encoder_hidden = self.encoder(batch_X, lengths_X)\n","        \n","        _batch_size = batch_X.size(1)\n","\n","        decoder_input = torch.tensor([BOS] * _batch_size, dtype=torch.long, device=device) \n","        decoder_input = decoder_input.unsqueeze(0)  \n","        decoder_hidden = encoder_hidden  \n","\n","        decoder_outputs = torch.zeros(max_length, _batch_size, self.decoder.output_size, device=device) \n","\n","        for t in range(max_length):\n","            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n","            decoder_outputs[t] = decoder_output\n","            if use_teacher_forcing and batch_Y is not None:  \n","                decoder_input = batch_Y[t].unsqueeze(0)\n","            else:  \n","                decoder_input = decoder_output.max(-1)[1]\n","                \n","        return decoder_outputs"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LVDsYtuVcgjC","executionInfo":{"status":"ok","timestamp":1626620698083,"user_tz":-540,"elapsed":7,"user":{"displayName":"石居拓己","photoUrl":"","userId":"06001050725637052584"}},"outputId":"4401c66e-c31e-4068-c622-bc204b832b82"},"source":["mce = nn.CrossEntropyLoss(size_average=False, ignore_index=PAD) \n","def masked_cross_entropy(logits, target):\n","    logits_flat = logits.view(-1, logits.size(-1)) \n","    target_flat = target.view(-1) \n","    return mce(logits_flat, target_flat)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n","  warnings.warn(warning.format(ret))\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"d5L0DkIkcgl9","executionInfo":{"status":"ok","timestamp":1626620709842,"user_tz":-540,"elapsed":11765,"user":{"displayName":"石居拓己","photoUrl":"","userId":"06001050725637052584"}}},"source":["num_epochs = 10\n","batch_size = 64\n","lr = 1e-3 \n","teacher_forcing_rate = 0.2  \n","ckpt_path = 'model.pth'  \n","\n","model_args = {\n","    'input_size': vocab_size_X,\n","    'output_size': vocab_size_Y,\n","    'hidden_size': 256,\n","}\n","\n","train_dataloader = DataLoader(train_X, train_Y, batch_size=batch_size, shuffle=True)\n","valid_dataloader = DataLoader(valid_X, valid_Y, batch_size=batch_size, shuffle=False)\n","\n","model = EncoderDecoder(**model_args).to(device)\n","optimizer = optim.Adam(model.parameters(), lr=lr)"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"knGg0qZKcgpJ","executionInfo":{"status":"ok","timestamp":1626620709844,"user_tz":-540,"elapsed":10,"user":{"displayName":"石居拓己","photoUrl":"","userId":"06001050725637052584"}}},"source":["def compute_loss(batch_X, batch_Y, lengths_X, model, optimizer=None, is_train=True):\n","    model.train(is_train)  \n","     \n","    use_teacher_forcing = is_train and (random.random() < teacher_forcing_rate)\n","    max_length = batch_Y.size(0)\n","\n","    pred_Y = model(batch_X, lengths_X, max_length, batch_Y, use_teacher_forcing)\n","    \n","    loss = masked_cross_entropy(pred_Y.contiguous(), batch_Y.contiguous())\n","    \n","    if is_train:  \n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","    \n","    batch_Y = batch_Y.transpose(0, 1).contiguous().data.cpu().tolist()\n","    pred = pred_Y.max(dim=-1)[1].data.cpu().numpy().T.tolist()\n","\n","    return loss.item(), batch_Y, pred"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"As_gOOd-heZV","executionInfo":{"status":"ok","timestamp":1626620709845,"user_tz":-540,"elapsed":10,"user":{"displayName":"石居拓己","photoUrl":"","userId":"06001050725637052584"}}},"source":["def calc_bleu(refs, hyps):\n","    refs = [[ref[:ref.index(EOS)]] for ref in refs] # EOSは評価しないで良いので切り捨てる, refsのほうは複数なのでlistが一個多くかかっている\n","    hyps = [hyp[:hyp.index(EOS)] if EOS in hyp else hyp for hyp in hyps]\n","    return 100 * bleu_score.corpus_bleu(refs, hyps)"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RHeFOFWyhecO","executionInfo":{"status":"ok","timestamp":1626620900499,"user_tz":-540,"elapsed":190664,"user":{"displayName":"石居拓己","photoUrl":"","userId":"06001050725637052584"}},"outputId":"e3089214-16fa-4ccf-c65e-ebc1f0c00a80"},"source":["# 訓練\n","best_valid_bleu = 0.\n","\n","for epoch in range(1, num_epochs+1):\n","    train_loss = 0.\n","    train_refs = []\n","    train_hyps = []\n","    valid_loss = 0.\n","    valid_refs = []\n","    valid_hyps = []\n","\n","    for batch in train_dataloader:\n","        batch_X, batch_Y, lengths_X = batch\n","        loss, gold, pred = compute_loss(\n","            batch_X, batch_Y, lengths_X, model, optimizer, \n","            is_train=True\n","            )\n","        train_loss += loss\n","        train_refs += gold\n","        train_hyps += pred\n","\n","    for batch in valid_dataloader:\n","        batch_X, batch_Y, lengths_X = batch\n","        loss, gold, pred = compute_loss(\n","            batch_X, batch_Y, lengths_X, model, \n","            is_train=False\n","            )\n","        valid_loss += loss\n","        valid_refs += gold\n","        valid_hyps += pred\n","\n","    train_loss = np.sum(train_loss) / len(train_dataloader.data)\n","    valid_loss = np.sum(valid_loss) / len(valid_dataloader.data)\n","\n","    train_bleu = calc_bleu(train_refs, train_hyps)\n","    valid_bleu = calc_bleu(valid_refs, valid_hyps)\n","\n","    if valid_bleu > best_valid_bleu:\n","        ckpt = model.state_dict()\n","        torch.save(ckpt, ckpt_path)\n","        best_valid_bleu = valid_bleu\n","\n","    print('Epoch {}: train_loss: {:5.2f}  train_bleu: {:2.2f}  valid_loss: {:5.2f}  valid_bleu: {:2.2f}'.format(\n","            epoch, train_loss, train_bleu, valid_loss, valid_bleu))\n","        \n","    print('-'*80)"],"execution_count":20,"outputs":[{"output_type":"stream","text":["Epoch 1: train_loss: 52.47  train_bleu: 3.18  valid_loss: 48.94  valid_bleu: 3.99\n","--------------------------------------------------------------------------------\n","Epoch 2: train_loss: 45.16  train_bleu: 7.07  valid_loss: 45.06  valid_bleu: 8.05\n","--------------------------------------------------------------------------------\n","Epoch 3: train_loss: 40.60  train_bleu: 10.89  valid_loss: 42.28  valid_bleu: 8.97\n","--------------------------------------------------------------------------------\n","Epoch 4: train_loss: 37.52  train_bleu: 13.96  valid_loss: 41.20  valid_bleu: 13.49\n","--------------------------------------------------------------------------------\n","Epoch 5: train_loss: 35.18  train_bleu: 16.33  valid_loss: 41.01  valid_bleu: 14.65\n","--------------------------------------------------------------------------------\n","Epoch 6: train_loss: 33.24  train_bleu: 18.72  valid_loss: 39.80  valid_bleu: 14.79\n","--------------------------------------------------------------------------------\n","Epoch 7: train_loss: 31.77  train_bleu: 20.54  valid_loss: 39.85  valid_bleu: 15.67\n","--------------------------------------------------------------------------------\n","Epoch 8: train_loss: 30.18  train_bleu: 22.82  valid_loss: 39.84  valid_bleu: 15.14\n","--------------------------------------------------------------------------------\n","Epoch 9: train_loss: 29.15  train_bleu: 24.51  valid_loss: 40.29  valid_bleu: 16.89\n","--------------------------------------------------------------------------------\n","Epoch 10: train_loss: 27.84  train_bleu: 26.54  valid_loss: 40.39  valid_bleu: 17.07\n","--------------------------------------------------------------------------------\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nUtkWYARhefd","executionInfo":{"status":"ok","timestamp":1626620900500,"user_tz":-540,"elapsed":21,"user":{"displayName":"石居拓己","photoUrl":"","userId":"06001050725637052584"}},"outputId":"b76f651a-9bea-4a1e-aff7-60b02bdb1c2c"},"source":["ckpt = torch.load(ckpt_path)\n","model.load_state_dict(ckpt)\n","model.eval()"],"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["EncoderDecoder(\n","  (encoder): Encoder(\n","    (embedding): Embedding(3725, 256, padding_idx=0)\n","    (gru): GRU(256, 256)\n","  )\n","  (decoder): Decoder(\n","    (embedding): Embedding(4405, 256, padding_idx=0)\n","    (gru): GRU(256, 256)\n","    (out): Linear(in_features=256, out_features=4405, bias=True)\n","  )\n",")"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"id":"Rojha_MyB475","executionInfo":{"status":"ok","timestamp":1626620900500,"user_tz":-540,"elapsed":8,"user":{"displayName":"石居拓己","photoUrl":"","userId":"06001050725637052584"}}},"source":["def ids_to_sentence(vocab, ids):\n","    return [vocab.id2word[_id] for _id in ids]\n","\n","def trim_eos(ids):\n","    if EOS in ids:\n","        return ids[:ids.index(EOS)]\n","    else:\n","        return ids"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"9QCH-dWRB5Ai","executionInfo":{"status":"ok","timestamp":1626620900501,"user_tz":-540,"elapsed":9,"user":{"displayName":"石居拓己","photoUrl":"","userId":"06001050725637052584"}}},"source":["test_X = load_data('./data/dev.en')\n","test_Y = load_data('./data/dev.ja')\n","\n","test_X = [sentence_to_ids(vocab_X, sentence) for sentence in test_X]\n","test_Y = [sentence_to_ids(vocab_Y, sentence) for sentence in test_Y]\n","\n","test_dataloader = DataLoader(test_X, test_Y, batch_size=1, shuffle=False)"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cPV7uiKHhemZ","executionInfo":{"status":"ok","timestamp":1626621013437,"user_tz":-540,"elapsed":224,"user":{"displayName":"石居拓己","photoUrl":"","userId":"06001050725637052584"}},"outputId":"eaef4204-00a8-4d05-e095-0755244578cc"},"source":["batch_X, batch_Y, lengths_X = next(test_dataloader)\n","sentence_X = ' '.join(ids_to_sentence(vocab_X, batch_X.data.cpu().numpy()[:-1, 0]))\n","sentence_Y = ' '.join(ids_to_sentence(vocab_Y, batch_Y.data.cpu().numpy()[:-1, 0]))\n","print('src: {}'.format(sentence_X))\n","print('tgt: {}'.format(sentence_Y))\n","\n","output = model(batch_X, lengths_X, max_length=20)\n","output = output.max(dim=-1)[1].view(-1).data.cpu().tolist()\n","output_sentence = ' '.join(ids_to_sentence(vocab_Y, trim_eos(output)))\n","output_sentence_without_trim = ' '.join(ids_to_sentence(vocab_Y, output))\n","print('out: {}'.format(output_sentence))\n","print('without trim: {}'.format(output_sentence_without_trim))"],"execution_count":28,"outputs":[{"output_type":"stream","text":["src: no . i 'm sorry , i 've got to go back early .\n","tgt: ごめん なさ い 。 早 く 帰 ら な く ちゃ 。\n","out: 早 く な く く く く く な り ま せ ん 。\n","without trim: 早 く な く く く く く な り ま せ ん 。 </S> </S> </S> </S> </S> </S>\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WkUxPL3CCW0G","executionInfo":{"status":"ok","timestamp":1626620903982,"user_tz":-540,"elapsed":3486,"user":{"displayName":"石居拓己","photoUrl":"","userId":"06001050725637052584"}},"outputId":"0170fcd3-0d84-4551-8115-ea36746e632f"},"source":["test_dataloader = DataLoader(test_X, test_Y, batch_size=1, shuffle=False)\n","refs_list = []\n","hyp_list = []\n","\n","for batch in test_dataloader:\n","    batch_X, batch_Y, lengths_X = batch\n","    pred_Y = model(batch_X, lengths_X, max_length=20)\n","    pred = pred_Y.max(dim=-1)[1].view(-1).data.cpu().tolist()\n","    refs = batch_Y.view(-1).data.cpu().tolist()\n","    refs_list.append(refs)\n","    hyp_list.append(pred)\n","bleu = calc_bleu(refs_list, hyp_list)\n","print(bleu)"],"execution_count":25,"outputs":[{"output_type":"stream","text":["16.72871429962597\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"VRhU87MyxIUV"},"source":["- NN機械翻訳の弱点  \n","最初に文章を一つのベクトルに集約している。その結果長い文章（情報量が多い）を用いると、ベクトルの表現力が足りなくなり、制度が悪くなる。  \n","- Attention(辞書オブジェクト)  \n","翻訳元で重要な単語に重みを置く。⇒ベクトルに集約するときに情報を失いにくい  \n","query,Key,Valueの三要素からなる。  \n","- Transformer  \n","Attensionをつかう。RNNを使わない。最初に位置情報を付与して計算を行う（RNNを使わないから)。  \n","- Self-Attention  \n","Attentionの一つ。度の単語が重要かを、自己完結で学習していく。  \n","- Scaled dot product attention  \n","全単語に関するAttentionをまとめて計算する。  \n","$$\n","    Attention(Q,K,V) = softmax \\left( \\frac{QK^T}{\\sqrt{d_k}} \\right) V\n","$$\n","- Multi-Head Attention  \n","Scaled dot product attentionを8個連結したもの。attentionの付け方を複数もたせて、アンサンブル学習ライクな効果を期待している。  \n","- Add&Norm  \n","Add:入出力の差分を学習させる（学習効率があがるテクニック）  \n","Norm:各層においてバイアスを除く活性化関数への入力を平均0、分散1に正則化(高速化テクニック）  \n","\n"]},{"cell_type":"markdown","metadata":{"id":"ewvrD7D644v3"},"source":["## 物体検知・セグメンテーション"]},{"cell_type":"markdown","metadata":{"id":"3z6cvTeh446j"},"source":["- 物体認識とは？  \n","画像を入力に受けて、物体認識をする。「分類」「物体件い」「意味領域分割」「個体領域分割」を行う。画像に対して、どこに何が移っているのか、を出力として与える。  \n","- データセット  \n","代表的なデータセットが存在し、それぞれに特徴がある。  \n","VOC12 : 物質ここにラベルが割り当てられている。クラス数20、データサイズ11540。Box/画像:2.4。  \n","ILSVRC17 : クラス数200、データ数476668、ImageNetのサブセット。Box/画像:1.1。  \n","MS COCO18 : 物質ここにラベルが割り当てられている。クラス数80,データ数123297。Box/画像:7.3。  \n","OICOD18 : 物質ここにラベルが割り当てられている。クラス数500、データ数1743042、Open ImagesV4のサブセット。Box/画像:7.0。  \n","- 評価指標  \n","まず通常のクラス分類問題の評価指標として、accuracy,precision,recall,(F)などがある。  \n","物体検出では、thresouldの変化に応じて、設定されるラベルの総数が変化する。  \n","- IoU: Intersection over Union : Jaccard係数  \n","$IoU = \\frac{TP}{TP+FP+FN}$となる。画素単位で計算する。物体検出では、confidenceのほかにIoUも閾値として設定されることになる。  \n","複数の画像を考える場合にも、TPFPの判断をして、Precision、Recallの計算をする。クラス単位でPrecisionとRecallの計算を行う。  \n","IoUを固定し、confidenceの閾値を変化させることでPR曲線を描くことができる（一般のクラス分類問題と同様）。PR曲線を描くことができれば、AP(PR曲線の下側面積）を求めることができる。クラスラベルごとに求めたAPの算術平均を求め、それをmAPと呼ぶ。（当たり前だが、なんでもかんでも”人”のラベルをつけるようなモデルはだめ）  \n","mAPはIoCの閾値の関数になるので、0.5から0.05刻みで平均を取ったmAPcocoのような指標もある。  \n","- 物体検知の大枠  \n","AlexNet以降にSIFT,DCNNへ。\n","- 代表的なネットワーク  \n","VGGNew, GoogLeNet(Inception-v1), ResNet, Inception-ResNet(Inception-v4), DenseNet,MobileNet,AmoebaNet。  \n","- 代表的な、物体検知のフレームワーク  \n"," - 2段階検出器:候補領域の検出とクラス推定を別々に行う。制度は良いが、遅い。   \n"," RCNN, SPPNet, Fast RCNN, Faster RCNN, RFCN, FPN, Mask RCNN  \n"," - 1段階検出器:候補領域の検出とクラス推定を同時に行う。制度は低いが、速い。  \n"," DetectorNet, YOLO, SSD, YOLO9000, RetinaNet, CornerNet  \n","- SSD  \n","以下の手順で出力をする。  \n"," 1. Default BOXを用意  \n"," 2. Default BOXを変形し、confidenceを出力する。  \n","SSDではVGG16を元にしたネットワークを用いる。VGG16はConvolution,Max Pooling, 全結合を組み合わせてネットワークを表現する。SSDでは、一部層構造を変更したうえで、解像度の異なるConv層から特徴マップを作成する。8000以上のDefault Boxが用意される。多数のBOXが用意されたために、1つの物体に複数のBOXが対応してしまうこともある。そのため、confidenceが最も近いものを選ぶようにする。  \n","\n","- Semantic Segmentationの肝  \n","物体検知では、各ピクセルごとにしゅつりょくを得るが、コンボリューション層とプーリング層では、画像のピクセルが落ちてしまう。これをどのように元のピクセル数に戻すのか（upsampling）が肝になる。  \n","- なぜPoolingが必要か？  \n","演算量をそこまで増やさずに、受容野を広げるため。  \n","- Deconvolution/Transposed convolution    \n","特徴マップのpixelに間隔をあけ、周囲に余白を作る。⇒畳み込み演算を行う。  \n","低レイヤーのPooling層の出力を足し算することで詳細情報を補完する。  \n"]}]}