{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "worse-notion",
   "metadata": {},
   "source": [
    "# 深層学習da3\n",
    "## Section1 : 再帰型ニューラルネットワークの概念"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formed-hindu",
   "metadata": {},
   "source": [
    "- 再帰型ニューラルネットワーク（RNN）  \n",
    "自然言語処理によく使われる方法。  \n",
    "特徴として、時系列データに対応することができるニューラルネットワーク。  \n",
    "具体的には、「音声データ」「株価データ」「テキストデータ（言語）」「博物館の入場者数」など。  \n",
    "- RNNの基本的構造  \n",
    "入力層-中間層-出力層という基本構造は、通常のニューラルネットワークと同じ。  \n",
    "RNNでは中間層からの出力を、「入力層から来たかのように」もう一度中間層に入れる。  \n",
    "- RNNでのパラメータ  \n",
    "RNNで考える重みパラメータは大きく3種類。入力データに係る$W_{(in)}$、中間層から中間層に係る$W$、出力層でかかる$W_{(out)}$  \n",
    "- RNNの数式での記述  \n",
    "$$\n",
    "u^t = W_{(in)}x^t + W z^{t-1} +b \\\\\n",
    "z^t = f(W_{(in)}x^t + Wz^{t-1} + b) \\\\\n",
    "v^t = W_{(out)}z^t + c \\\\\n",
    "y^t = g(W_{(out)}z^t + c)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infinite-review",
   "metadata": {},
   "source": [
    "以下、Pythonコードでの実装を確認する(バイナリ加算)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "alpine-handy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "native-extreme",
   "metadata": {},
   "outputs": [],
   "source": [
    "def d_tanh(x):\n",
    "    return 1/ (np.cosh(x) ** 2)\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/ (1 + np.exp(-x))\n",
    "\n",
    "def mean_squared_error(d, y):\n",
    "    return np.mean(np.square(d - y)) / 2\n",
    "\n",
    "def d_sigmoid(x):\n",
    "    dx = (1.0 - sigmoid(x)) * sigmoid(x)\n",
    "    return dx\n",
    "\n",
    "def d_mean_squared_error(d, y):\n",
    "    if type(d) == np.ndarray:\n",
    "        batch_size = d.shape[0]\n",
    "        dx = (y - d)/batch_size\n",
    "    else:\n",
    "        dx = y - d\n",
    "    return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ambient-spirit",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_dim = 8\n",
    "largest_number = pow(2, binary_dim)\n",
    "binary = np.unpackbits(np.array([range(largest_number)],dtype=np.uint8).T, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "painted-innocent",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 8)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "international-accident",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初期値の設定\n",
    "input_layer_size = 2\n",
    "hidden_layer_size = 16\n",
    "output_layer_size = 1\n",
    "\n",
    "weight_init_std = 1\n",
    "learning_rate = 0.1\n",
    "\n",
    "iters_num = 10000\n",
    "plot_interval = 100\n",
    "\n",
    "W_in = weight_init_std * np.random.randn(input_layer_size, hidden_layer_size)\n",
    "W_out = weight_init_std * np.random.randn(hidden_layer_size, output_layer_size)\n",
    "W = weight_init_std * np.random.randn(hidden_layer_size, hidden_layer_size)\n",
    "\n",
    "W_in_grad = np.zeros_like(W_in)\n",
    "W_out_grad = np.zeros_like(W_out)\n",
    "W_grad = np.zeros_like(W)\n",
    "\n",
    "u = np.zeros((hidden_layer_size, binary_dim + 1))\n",
    "z = np.zeros((hidden_layer_size, binary_dim + 1))\n",
    "y = np.zeros((output_layer_size, binary_dim))\n",
    "\n",
    "delta_out = np.zeros((output_layer_size, binary_dim))\n",
    "delta = np.zeros((hidden_layer_size, binary_dim + 1))\n",
    "\n",
    "all_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "meaningful-radio",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iters:0\n",
      "Loss :1.2728704522174796\n",
      "Pred :[1 1 1 1 1 1 1 1]\n",
      "True :[1 0 0 1 0 1 1 0]\n",
      "40 + 110 = 255\n",
      "----------\n",
      "iters:100\n",
      "Loss :1.1833347644106869\n",
      "Pred :[0 0 0 0 0 0 1 1]\n",
      "True :[1 0 1 1 1 0 0 0]\n",
      "76 + 108 = 3\n",
      "----------\n",
      "iters:200\n",
      "Loss :1.1061369248791877\n",
      "Pred :[0 1 1 1 1 1 1 1]\n",
      "True :[1 0 1 1 0 1 0 1]\n",
      "123 + 58 = 127\n",
      "----------\n",
      "iters:300\n",
      "Loss :1.0878728364660748\n",
      "Pred :[0 0 0 0 0 0 1 0]\n",
      "True :[1 0 0 1 0 1 1 1]\n",
      "98 + 53 = 2\n",
      "----------\n",
      "iters:400\n",
      "Loss :1.0832243832242292\n",
      "Pred :[0 0 0 0 0 0 0 0]\n",
      "True :[0 1 0 1 1 1 1 0]\n",
      "46 + 48 = 0\n",
      "----------\n",
      "iters:500\n",
      "Loss :0.894343608737821\n",
      "Pred :[1 0 1 0 0 0 0 0]\n",
      "True :[1 0 1 0 1 0 0 1]\n",
      "81 + 88 = 160\n",
      "----------\n",
      "iters:600\n",
      "Loss :1.0169045553554095\n",
      "Pred :[1 0 1 0 1 1 1 0]\n",
      "True :[1 0 0 0 1 1 1 1]\n",
      "87 + 56 = 174\n",
      "----------\n",
      "iters:700\n",
      "Loss :0.9919654814116694\n",
      "Pred :[1 1 1 1 0 0 0 1]\n",
      "True :[1 0 1 1 0 0 0 0]\n",
      "120 + 56 = 241\n",
      "----------\n",
      "iters:800\n",
      "Loss :0.9987158181232302\n",
      "Pred :[1 0 0 0 0 0 0 0]\n",
      "True :[0 1 1 1 0 0 0 1]\n",
      "4 + 109 = 128\n",
      "----------\n",
      "iters:900\n",
      "Loss :0.8840062036645906\n",
      "Pred :[0 0 0 0 0 1 0 0]\n",
      "True :[0 0 1 0 0 0 0 1]\n",
      "26 + 7 = 4\n",
      "----------\n",
      "iters:1000\n",
      "Loss :1.0900922096051517\n",
      "Pred :[0 0 0 0 0 0 0 0]\n",
      "True :[1 0 1 1 0 1 0 1]\n",
      "92 + 89 = 0\n",
      "----------\n",
      "iters:1100\n",
      "Loss :0.9862354118613287\n",
      "Pred :[1 1 1 1 1 1 1 1]\n",
      "True :[0 1 1 1 1 0 1 0]\n",
      "49 + 73 = 255\n",
      "----------\n",
      "iters:1200\n",
      "Loss :0.9607568259043591\n",
      "Pred :[1 0 0 1 0 1 1 1]\n",
      "True :[1 1 0 0 0 1 1 1]\n",
      "88 + 111 = 151\n",
      "----------\n",
      "iters:1300\n",
      "Loss :0.9787984065570279\n",
      "Pred :[1 1 1 0 0 0 0 1]\n",
      "True :[0 1 1 1 0 1 1 1]\n",
      "6 + 113 = 225\n",
      "----------\n",
      "iters:1400\n",
      "Loss :0.9025628261210076\n",
      "Pred :[0 1 1 0 0 1 1 0]\n",
      "True :[0 1 1 1 0 0 1 0]\n",
      "55 + 59 = 102\n",
      "----------\n",
      "iters:1500\n",
      "Loss :0.7690447965602861\n",
      "Pred :[1 0 0 1 1 1 1 1]\n",
      "True :[1 0 0 1 1 1 0 1]\n",
      "78 + 79 = 159\n",
      "----------\n",
      "iters:1600\n",
      "Loss :0.5544190974495758\n",
      "Pred :[0 0 0 0 0 1 0 0]\n",
      "True :[0 0 0 0 0 1 0 0]\n",
      "2 + 2 = 4\n",
      "----------\n",
      "iters:1700\n",
      "Loss :0.959817542126653\n",
      "Pred :[1 1 1 0 1 1 1 0]\n",
      "True :[1 0 0 0 1 1 1 1]\n",
      "121 + 22 = 238\n",
      "----------\n",
      "iters:1800\n",
      "Loss :0.9519113130932363\n",
      "Pred :[1 1 1 1 1 1 1 0]\n",
      "True :[1 1 0 0 1 0 0 0]\n",
      "91 + 109 = 254\n",
      "----------\n",
      "iters:1900\n",
      "Loss :0.9097496687223692\n",
      "Pred :[1 0 1 0 1 1 0 1]\n",
      "True :[1 0 1 1 0 0 0 1]\n",
      "82 + 95 = 173\n",
      "----------\n",
      "iters:2000\n",
      "Loss :0.9201778272450067\n",
      "Pred :[1 1 1 1 1 1 1 1]\n",
      "True :[1 1 0 0 1 1 1 1]\n",
      "86 + 121 = 255\n",
      "----------\n",
      "iters:2100\n",
      "Loss :1.1691433611386282\n",
      "Pred :[0 1 0 0 0 0 0 0]\n",
      "True :[1 0 0 1 0 1 1 1]\n",
      "54 + 97 = 64\n",
      "----------\n",
      "iters:2200\n",
      "Loss :0.8830922645648152\n",
      "Pred :[0 1 1 0 0 1 0 0]\n",
      "True :[0 1 1 1 0 0 1 0]\n",
      "55 + 59 = 100\n",
      "----------\n",
      "iters:2300\n",
      "Loss :0.9218012060445646\n",
      "Pred :[1 1 0 1 1 1 1 0]\n",
      "True :[1 0 0 1 1 1 0 0]\n",
      "45 + 111 = 222\n",
      "----------\n",
      "iters:2400\n",
      "Loss :0.8993184273441216\n",
      "Pred :[0 1 1 0 1 0 0 1]\n",
      "True :[0 0 1 1 1 0 1 0]\n",
      "22 + 36 = 105\n",
      "----------\n",
      "iters:2500\n",
      "Loss :0.8757486414295339\n",
      "Pred :[0 0 0 0 1 0 1 0]\n",
      "True :[0 1 1 0 1 0 1 0]\n",
      "13 + 93 = 10\n",
      "----------\n",
      "iters:2600\n",
      "Loss :1.0712830750199087\n",
      "Pred :[0 1 1 0 1 1 1 1]\n",
      "True :[1 0 0 0 0 0 1 1]\n",
      "116 + 15 = 111\n",
      "----------\n",
      "iters:2700\n",
      "Loss :1.0040312295461056\n",
      "Pred :[0 0 1 0 0 0 0 0]\n",
      "True :[1 0 0 0 0 0 1 1]\n",
      "95 + 36 = 32\n",
      "----------\n",
      "iters:2800\n",
      "Loss :1.0542372953685297\n",
      "Pred :[0 0 0 0 0 0 0 1]\n",
      "True :[1 0 0 1 0 1 1 1]\n",
      "118 + 33 = 1\n",
      "----------\n",
      "iters:2900\n",
      "Loss :0.8474813621136715\n",
      "Pred :[1 0 1 0 1 1 0 1]\n",
      "True :[1 0 1 0 1 1 1 1]\n",
      "82 + 93 = 173\n",
      "----------\n",
      "iters:3000\n",
      "Loss :0.9420649622011263\n",
      "Pred :[1 1 1 0 1 0 0 1]\n",
      "True :[1 0 0 0 1 0 1 1]\n",
      "55 + 84 = 233\n",
      "----------\n",
      "iters:3100\n",
      "Loss :0.839983599667374\n",
      "Pred :[1 1 1 0 0 0 1 1]\n",
      "True :[1 0 0 0 0 0 1 0]\n",
      "16 + 114 = 227\n",
      "----------\n",
      "iters:3200\n",
      "Loss :0.628682271787185\n",
      "Pred :[0 1 1 0 0 1 1 0]\n",
      "True :[0 1 1 0 1 1 1 0]\n",
      "41 + 69 = 102\n",
      "----------\n",
      "iters:3300\n",
      "Loss :0.47926699064036504\n",
      "Pred :[0 1 1 1 1 0 1 1]\n",
      "True :[0 1 1 1 1 0 1 0]\n",
      "30 + 92 = 123\n",
      "----------\n",
      "iters:3400\n",
      "Loss :0.662378668260441\n",
      "Pred :[1 0 1 0 1 1 1 1]\n",
      "True :[1 1 0 0 1 1 1 1]\n",
      "85 + 122 = 175\n",
      "----------\n",
      "iters:3500\n",
      "Loss :0.6004903398872269\n",
      "Pred :[0 1 0 1 1 1 1 1]\n",
      "True :[0 1 0 1 1 1 1 0]\n",
      "82 + 12 = 95\n",
      "----------\n",
      "iters:3600\n",
      "Loss :0.589702600578264\n",
      "Pred :[0 0 0 1 0 1 1 0]\n",
      "True :[0 0 1 1 0 1 1 0]\n",
      "37 + 17 = 22\n",
      "----------\n",
      "iters:3700\n",
      "Loss :0.499325568644047\n",
      "Pred :[0 0 1 1 0 0 1 1]\n",
      "True :[0 0 1 1 0 1 1 0]\n",
      "46 + 8 = 51\n",
      "----------\n",
      "iters:3800\n",
      "Loss :0.46599689963406854\n",
      "Pred :[0 1 0 1 0 1 0 1]\n",
      "True :[0 1 0 1 1 1 0 1]\n",
      "77 + 16 = 85\n",
      "----------\n",
      "iters:3900\n",
      "Loss :0.9283888904444126\n",
      "Pred :[1 0 1 0 1 1 0 0]\n",
      "True :[1 1 0 0 0 0 0 0]\n",
      "115 + 77 = 172\n",
      "----------\n",
      "iters:4000\n",
      "Loss :0.4741954352859576\n",
      "Pred :[0 1 0 1 0 0 0 1]\n",
      "True :[0 1 0 1 0 0 0 1]\n",
      "27 + 54 = 81\n",
      "----------\n",
      "iters:4100\n",
      "Loss :0.1704495646436638\n",
      "Pred :[1 0 0 1 0 1 0 0]\n",
      "True :[1 0 0 1 0 1 0 0]\n",
      "76 + 72 = 148\n",
      "----------\n",
      "iters:4200\n",
      "Loss :0.2878153087075024\n",
      "Pred :[0 1 1 0 0 1 1 0]\n",
      "True :[0 1 1 0 0 1 1 0]\n",
      "4 + 98 = 102\n",
      "----------\n",
      "iters:4300\n",
      "Loss :0.7517170465726953\n",
      "Pred :[0 1 1 1 0 0 1 1]\n",
      "True :[0 1 0 0 0 0 0 1]\n",
      "12 + 53 = 115\n",
      "----------\n",
      "iters:4400\n",
      "Loss :0.769531415911997\n",
      "Pred :[1 0 1 1 0 0 0 0]\n",
      "True :[1 1 0 0 0 0 0 0]\n",
      "116 + 76 = 176\n",
      "----------\n",
      "iters:4500\n",
      "Loss :0.07599335472539999\n",
      "Pred :[0 0 1 0 1 1 0 0]\n",
      "True :[0 0 1 0 1 1 0 0]\n",
      "27 + 17 = 44\n",
      "----------\n",
      "iters:4600\n",
      "Loss :0.19664183956433282\n",
      "Pred :[0 1 1 1 1 0 0 1]\n",
      "True :[0 1 1 1 1 0 0 1]\n",
      "110 + 11 = 121\n",
      "----------\n",
      "iters:4700\n",
      "Loss :0.19169140945048424\n",
      "Pred :[1 0 0 1 0 1 0 1]\n",
      "True :[1 0 0 1 0 1 0 1]\n",
      "74 + 75 = 149\n",
      "----------\n",
      "iters:4800\n",
      "Loss :0.26347675354389954\n",
      "Pred :[0 1 0 1 0 1 1 1]\n",
      "True :[0 1 0 1 0 1 1 1]\n",
      "47 + 40 = 87\n",
      "----------\n",
      "iters:4900\n",
      "Loss :0.2150715794375337\n",
      "Pred :[0 1 1 1 1 0 0 0]\n",
      "True :[0 1 1 1 1 0 0 0]\n",
      "26 + 94 = 120\n",
      "----------\n",
      "iters:5000\n",
      "Loss :0.06272120063108691\n",
      "Pred :[1 0 1 0 1 1 1 1]\n",
      "True :[1 0 1 0 1 1 1 1]\n",
      "95 + 80 = 175\n",
      "----------\n",
      "iters:5100\n",
      "Loss :0.08226016169818336\n",
      "Pred :[0 1 1 0 1 1 0 1]\n",
      "True :[0 1 1 0 1 1 0 1]\n",
      "15 + 94 = 109\n",
      "----------\n",
      "iters:5200\n",
      "Loss :0.04216618496079661\n",
      "Pred :[0 0 0 1 1 1 0 1]\n",
      "True :[0 0 0 1 1 1 0 1]\n",
      "19 + 10 = 29\n",
      "----------\n",
      "iters:5300\n",
      "Loss :0.03160495479197794\n",
      "Pred :[1 0 1 0 0 0 0 1]\n",
      "True :[1 0 1 0 0 0 0 1]\n",
      "97 + 64 = 161\n",
      "----------\n",
      "iters:5400\n",
      "Loss :0.06746520526366859\n",
      "Pred :[0 1 1 0 0 1 0 0]\n",
      "True :[0 1 1 0 0 1 0 0]\n",
      "84 + 16 = 100\n",
      "----------\n",
      "iters:5500\n",
      "Loss :0.05565572925076068\n",
      "Pred :[0 0 1 0 1 1 1 0]\n",
      "True :[0 0 1 0 1 1 1 0]\n",
      "10 + 36 = 46\n",
      "----------\n",
      "iters:5600\n",
      "Loss :0.04895976403316302\n",
      "Pred :[0 0 1 1 1 0 0 1]\n",
      "True :[0 0 1 1 1 0 0 1]\n",
      "43 + 14 = 57\n",
      "----------\n",
      "iters:5700\n",
      "Loss :0.047774079414854426\n",
      "Pred :[0 1 0 0 1 0 0 0]\n",
      "True :[0 1 0 0 1 0 0 0]\n",
      "8 + 64 = 72\n",
      "----------\n",
      "iters:5800\n",
      "Loss :0.04043774524963555\n",
      "Pred :[1 1 1 1 0 0 1 1]\n",
      "True :[1 1 1 1 0 0 1 1]\n",
      "126 + 117 = 243\n",
      "----------\n",
      "iters:5900\n",
      "Loss :0.06413478396767126\n",
      "Pred :[1 0 1 1 0 0 1 1]\n",
      "True :[1 0 1 1 0 0 1 1]\n",
      "80 + 99 = 179\n",
      "----------\n",
      "iters:6000\n",
      "Loss :0.033352179034160816\n",
      "Pred :[0 1 1 1 1 0 0 1]\n",
      "True :[0 1 1 1 1 0 0 1]\n",
      "60 + 61 = 121\n",
      "----------\n",
      "iters:6100\n",
      "Loss :0.021165387908132386\n",
      "Pred :[1 0 0 1 0 0 1 1]\n",
      "True :[1 0 0 1 0 0 1 1]\n",
      "119 + 28 = 147\n",
      "----------\n",
      "iters:6200\n",
      "Loss :0.019884752390177122\n",
      "Pred :[0 1 1 1 0 1 0 1]\n",
      "True :[0 1 1 1 0 1 0 1]\n",
      "30 + 87 = 117\n",
      "----------\n",
      "iters:6300\n",
      "Loss :0.006192190093058006\n",
      "Pred :[1 0 0 1 0 1 1 0]\n",
      "True :[1 0 0 1 0 1 1 0]\n",
      "75 + 75 = 150\n",
      "----------\n",
      "iters:6400\n",
      "Loss :0.06710795513052832\n",
      "Pred :[0 0 1 1 1 1 1 1]\n",
      "True :[0 0 1 1 1 1 1 1]\n",
      "24 + 39 = 63\n",
      "----------\n",
      "iters:6500\n",
      "Loss :0.003984684918419316\n",
      "Pred :[1 1 0 0 0 1 1 0]\n",
      "True :[1 1 0 0 0 1 1 0]\n",
      "125 + 73 = 198\n",
      "----------\n",
      "iters:6600\n",
      "Loss :0.021757234691850365\n",
      "Pred :[1 0 0 1 1 0 1 0]\n",
      "True :[1 0 0 1 1 0 1 0]\n",
      "29 + 125 = 154\n",
      "----------\n",
      "iters:6700\n",
      "Loss :0.022492241632922558\n",
      "Pred :[0 1 1 1 1 1 1 0]\n",
      "True :[0 1 1 1 1 1 1 0]\n",
      "30 + 96 = 126\n",
      "----------\n",
      "iters:6800\n",
      "Loss :0.03393875435759771\n",
      "Pred :[1 0 0 1 1 1 1 0]\n",
      "True :[1 0 0 1 1 1 1 0]\n",
      "44 + 114 = 158\n",
      "----------\n",
      "iters:6900\n",
      "Loss :0.008125119048313357\n",
      "Pred :[1 0 1 0 1 1 0 0]\n",
      "True :[1 0 1 0 1 1 0 0]\n",
      "101 + 71 = 172\n",
      "----------\n",
      "iters:7000\n",
      "Loss :0.012302483080010512\n",
      "Pred :[1 0 0 0 0 1 1 0]\n",
      "True :[1 0 0 0 0 1 1 0]\n",
      "13 + 121 = 134\n",
      "----------\n",
      "iters:7100\n",
      "Loss :0.019479309721371612\n",
      "Pred :[0 1 0 1 1 0 1 1]\n",
      "True :[0 1 0 1 1 0 1 1]\n",
      "16 + 75 = 91\n",
      "----------\n",
      "iters:7200\n",
      "Loss :0.018787940640182466\n",
      "Pred :[0 1 0 0 0 0 1 1]\n",
      "True :[0 1 0 0 0 0 1 1]\n",
      "6 + 61 = 67\n",
      "----------\n",
      "iters:7300\n",
      "Loss :0.011731905943154297\n",
      "Pred :[1 0 1 1 0 0 0 1]\n",
      "True :[1 0 1 1 0 0 0 1]\n",
      "98 + 79 = 177\n",
      "----------\n",
      "iters:7400\n",
      "Loss :0.016613830823330653\n",
      "Pred :[1 0 1 0 1 0 1 1]\n",
      "True :[1 0 1 0 1 0 1 1]\n",
      "120 + 51 = 171\n",
      "----------\n",
      "iters:7500\n",
      "Loss :0.0006620343105511869\n",
      "Pred :[0 0 1 1 0 0 1 0]\n",
      "True :[0 0 1 1 0 0 1 0]\n",
      "49 + 1 = 50\n",
      "----------\n",
      "iters:7600\n",
      "Loss :0.00968408374565254\n",
      "Pred :[0 1 1 1 0 0 1 1]\n",
      "True :[0 1 1 1 0 0 1 1]\n",
      "42 + 73 = 115\n",
      "----------\n",
      "iters:7700\n",
      "Loss :0.0070735040910567875\n",
      "Pred :[0 1 1 0 1 0 1 1]\n",
      "True :[0 1 1 0 1 0 1 1]\n",
      "2 + 105 = 107\n",
      "----------\n",
      "iters:7800\n",
      "Loss :0.00537063265183174\n",
      "Pred :[0 1 1 1 1 0 1 1]\n",
      "True :[0 1 1 1 1 0 1 1]\n",
      "51 + 72 = 123\n",
      "----------\n",
      "iters:7900\n",
      "Loss :0.0012357709655279668\n",
      "Pred :[1 0 1 1 0 0 1 0]\n",
      "True :[1 0 1 1 0 0 1 0]\n",
      "81 + 97 = 178\n",
      "----------\n",
      "iters:8000\n",
      "Loss :0.005442938524171865\n",
      "Pred :[0 1 1 1 0 0 0 1]\n",
      "True :[0 1 1 1 0 0 0 1]\n",
      "108 + 5 = 113\n",
      "----------\n",
      "iters:8100\n",
      "Loss :0.012354999656189095\n",
      "Pred :[0 0 1 1 0 0 1 0]\n",
      "True :[0 0 1 1 0 0 1 0]\n",
      "6 + 44 = 50\n",
      "----------\n",
      "iters:8200\n",
      "Loss :0.013346969183920853\n",
      "Pred :[0 1 0 1 0 0 1 0]\n",
      "True :[0 1 0 1 0 0 1 0]\n",
      "6 + 76 = 82\n",
      "----------\n",
      "iters:8300\n",
      "Loss :0.004931018685492903\n",
      "Pred :[1 0 0 0 1 0 0 1]\n",
      "True :[1 0 0 0 1 0 0 1]\n",
      "104 + 33 = 137\n",
      "----------\n",
      "iters:8400\n",
      "Loss :0.01089700093228096\n",
      "Pred :[1 0 1 0 0 1 0 0]\n",
      "True :[1 0 1 0 0 1 0 0]\n",
      "56 + 108 = 164\n",
      "----------\n",
      "iters:8500\n",
      "Loss :0.008956932226232816\n",
      "Pred :[0 0 1 1 1 1 1 0]\n",
      "True :[0 0 1 1 1 1 1 0]\n",
      "4 + 58 = 62\n",
      "----------\n",
      "iters:8600\n",
      "Loss :0.00454101176283518\n",
      "Pred :[0 1 1 0 0 0 1 1]\n",
      "True :[0 1 1 0 0 0 1 1]\n",
      "1 + 98 = 99\n",
      "----------\n",
      "iters:8700\n",
      "Loss :0.003501282692431077\n",
      "Pred :[0 1 1 0 0 0 0 1]\n",
      "True :[0 1 1 0 0 0 0 1]\n",
      "89 + 8 = 97\n",
      "----------\n",
      "iters:8800\n",
      "Loss :0.0051824670382697065\n",
      "Pred :[0 1 1 1 1 1 1 1]\n",
      "True :[0 1 1 1 1 1 1 1]\n",
      "40 + 87 = 127\n",
      "----------\n",
      "iters:8900\n",
      "Loss :0.0023887154398418782\n",
      "Pred :[0 1 0 0 0 1 0 1]\n",
      "True :[0 1 0 0 0 1 0 1]\n",
      "57 + 12 = 69\n",
      "----------\n",
      "iters:9000\n",
      "Loss :0.0033875852419824265\n",
      "Pred :[1 1 0 0 0 0 1 1]\n",
      "True :[1 1 0 0 0 0 1 1]\n",
      "101 + 94 = 195\n",
      "----------\n",
      "iters:9100\n",
      "Loss :0.0020865199345859154\n",
      "Pred :[1 0 0 1 1 1 0 0]\n",
      "True :[1 0 0 1 1 1 0 0]\n",
      "65 + 91 = 156\n",
      "----------\n",
      "iters:9200\n",
      "Loss :0.0016722786161475285\n",
      "Pred :[0 0 1 1 1 0 0 1]\n",
      "True :[0 0 1 1 1 0 0 1]\n",
      "57 + 0 = 57\n",
      "----------\n",
      "iters:9300\n",
      "Loss :0.002922383879331913\n",
      "Pred :[0 1 0 1 1 0 0 1]\n",
      "True :[0 1 0 1 1 0 0 1]\n",
      "8 + 81 = 89\n",
      "----------\n",
      "iters:9400\n",
      "Loss :0.005945599359026222\n",
      "Pred :[0 1 1 0 0 1 1 0]\n",
      "True :[0 1 1 0 0 1 1 0]\n",
      "42 + 60 = 102\n",
      "----------\n",
      "iters:9500\n",
      "Loss :0.005764520469388336\n",
      "Pred :[0 0 1 0 1 1 1 0]\n",
      "True :[0 0 1 0 1 1 1 0]\n",
      "20 + 26 = 46\n",
      "----------\n",
      "iters:9600\n",
      "Loss :0.005132278469553252\n",
      "Pred :[1 0 0 0 1 1 1 0]\n",
      "True :[1 0 0 0 1 1 1 0]\n",
      "68 + 74 = 142\n",
      "----------\n",
      "iters:9700\n",
      "Loss :0.0021440535948931768\n",
      "Pred :[0 1 1 0 0 1 0 1]\n",
      "True :[0 1 1 0 0 1 0 1]\n",
      "45 + 56 = 101\n",
      "----------\n",
      "iters:9800\n",
      "Loss :0.0002479234738034561\n",
      "Pred :[0 1 1 0 0 1 1 0]\n",
      "True :[0 1 1 0 0 1 1 0]\n",
      "69 + 33 = 102\n",
      "----------\n",
      "iters:9900\n",
      "Loss :0.004350658280509649\n",
      "Pred :[0 1 1 0 0 1 1 0]\n",
      "True :[0 1 1 0 0 1 1 0]\n",
      "84 + 18 = 102\n",
      "----------\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(iters_num):\n",
    "    a_int = np.random.randint(largest_number / 2)\n",
    "    a_bin = binary[a_int]\n",
    "    b_int = np.random.randint(largest_number / 2)\n",
    "    b_bin = binary[b_int]\n",
    "    \n",
    "    d_int = a_int + b_int\n",
    "    d_bin = binary[d_int]\n",
    "    \n",
    "    out_bin = np.zeros_like(d_bin)\n",
    "    \n",
    "    all_loss = 0\n",
    "    \n",
    "    # 順伝播 tをずらしながら（時系列として）学習を進める。\n",
    "    for t in range(binary_dim):\n",
    "        X = np.array([a_bin[-t-1], b_bin[-t-1]]).reshape(1,-1)\n",
    "        dd = np.array([d_bin[binary_dim - t - 1]])\n",
    "        \n",
    "        u[:,t+1] = np.dot(X, W_in) + np.dot(z[:, t].reshape(1, -1), W)\n",
    "        z[:,t+1] = sigmoid(u[:,t+1])\n",
    "        y[:,t] = sigmoid(np.dot(z[:,t+1].reshape(1,-1), W_out))\n",
    "        \n",
    "        loss = mean_squared_error(dd, y[:,t])\n",
    "        \n",
    "        delta_out[:,t] = d_mean_squared_error(dd, y[:,t]) * d_sigmoid(y[:,t])\n",
    "        \n",
    "        all_loss += loss\n",
    "        \n",
    "        out_bin[binary_dim - t - 1] = np.round(y[:,t])\n",
    "    \n",
    "    # 逆伝播\n",
    "    for t in range(binary_dim)[::-1]:\n",
    "        X = np.array([a_bin[-t-1],b_bin[-t-1]]).reshape(1, -1)\n",
    "        \n",
    "        delta[:,t] = (np.dot(delta[:,t+1].T, W.T) + \n",
    "                      np.dot(delta_out[:,t].T, W_out.T)) * d_sigmoid(u[:,t+1])\n",
    "        \n",
    "        # 勾配の更新\n",
    "        W_out_grad += np.dot(z[:,t+1].reshape(-1,1), delta_out[:,t].reshape(-1,1))\n",
    "        W_grad += np.dot(z[:,t].reshape(-1,1), delta[:,t].reshape(1,-1))\n",
    "        W_in_grad += np.dot(X.T, delta[:,t].reshape(1,-1))\n",
    "        \n",
    "    W_in -= learning_rate * W_in_grad\n",
    "    W_out -= learning_rate * W_out_grad\n",
    "    W -= learning_rate * W_grad\n",
    "\n",
    "    W_in_grad *= 0\n",
    "    W_out_grad *= 0\n",
    "    W_grad *= 0\n",
    "\n",
    "    if(i % plot_interval == 0):\n",
    "        all_losses.append(all_loss)\n",
    "        print(\"iters:\" + str(i))\n",
    "        print(\"Loss :\" + str(all_loss))\n",
    "        print(\"Pred :\" + str(out_bin))\n",
    "        print(\"True :\" + str(d_bin))\n",
    "        out_int = 0\n",
    "        for index, x in enumerate(reversed(out_bin)):\n",
    "            out_int += x * pow(2, index)\n",
    "        print(str(a_int) + \" + \" + str(b_int) + \" = \" + str(out_int))\n",
    "        print(\"----------\")\n",
    "            \n",
    "lists = range(0, iters_num, plot_interval)\n",
    "plt.plot(lists, all_losses, label = \"loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "likely-cause",
   "metadata": {},
   "source": [
    "- 逆伝播の復習\n",
    "ニューラルネットワークの出力層の側から、微分値を掛け合わせながら進んでいくことで、各層でのパラメータによる微分を求めることができる。(これをパラメータ更新に利用する)\n",
    "- RNNにおける逆伝播とは？→BPTT  \n",
    "RNNの更新するパラメータは3つある$W_{(in)},W_{(out)},W$。それぞれについて、通常と同様に微分の連鎖率を用いて計算できる。\n",
    "$$\n",
    "    \\frac{\\partial E}{\\partial W_{(in)}} = \\frac{\\partial E}{\\partial u^t}\\left[\\frac{\\partial u^t}{\\partial W_{(in)}}\\right]^T = \\delta ^t[x^t]^T\\\\\n",
    "    \\frac{\\partial E}{\\partial W_{(out)}} = \\frac{\\partial E}{\\partial v^t}\\left[\\frac{\\partial v^t}{\\partial W_{(out)}}\\right]^T = \\delta ^{out,t}[z^t]^T\\\\\n",
    "    \\frac{\\partial E}{\\partial W} = \\frac{\\partial E}{\\partial u^t}\\left[\\frac{\\partial u^t}{\\partial W}\\right]^T = \\delta ^t[z^{t-1}]^T\\\\\n",
    "    \\frac{\\partial E}{\\partial b} = \\frac{\\partial E}{\\partial u^t}\\frac{\\partial u^t}{\\partial b} = \\delta ^t \\\\\n",
    "    \\frac{\\partial E}{\\partial c} = \\frac{\\partial E}{\\partial v^t}\\frac{\\partial v^t}{\\partial c} = \\delta ^{out,t}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b78a7e28-3bb1-4ecf-90fb-b264a792fa5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 演習チャレンジのコード実装\n",
    "def traverse(node):\n",
    "    \"\"\"\n",
    "    構文木を入力として文全体の表現ベクトルを得るプログラム\n",
    "    \"\"\"\n",
    "    if not isinstance(node, dict):\n",
    "        v = node\n",
    "    else:\n",
    "        # 再帰的に左右の子ノードを処理\n",
    "        left = traverse(node[\"left\"])\n",
    "        right = traverse(node[\"right\"])\n",
    "        \n",
    "        # 活性化関数をかませて表現ベクトルを得る。 \n",
    "        # Wはグローバルに定義されている。\n",
    "        v = _activation(W.dot(np.concatenate([left, right])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7908248e-3a55-44cb-8293-21c6e9bd59d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 演習チャレンジのコード実装例\n",
    "def bptt(xs, ys, W, U, V):\n",
    "    \"\"\"\n",
    "    BPTTによる逆伝播の計算\n",
    "    \"\"\"\n",
    "    hiddens, outputs = rnn_net(xs, W, U, V) # 多分、レイヤーを返す関数\n",
    "    \n",
    "    # 初期化\n",
    "    dW = np.zeros_like(W)\n",
    "    dU = np.zeros_like(U)\n",
    "    dV = np.zeros_like(V)\n",
    "    \n",
    "    do = _calculate_do(outputs, ys)\n",
    "    \n",
    "    batch_size, n_seq = ys.shape[:2]\n",
    "    \n",
    "    #ここからバックプロパゲーションの計算\n",
    "    for t in reversed(range(n_seq)):\n",
    "        dV += np.dot(do[:, t].T, hiddens[:, t]) / batch_size\n",
    "        delta_t = do[:, t].dot(V)\n",
    "        for bptt_step in reversed(range(t+1)):\n",
    "            dW += np.dot(delta_t.T, xs[:, bptt_step]) / batch_size\n",
    "            dU += np.dot(delta_t.T, hiddens[:, bptt_step - 1]) / batch_size\n",
    "            delta_t = delta_t.dot(U)\n",
    "    return dW, dU, dV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "juvenile-shakespeare",
   "metadata": {},
   "source": [
    "## Section2 : LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "returning-korea",
   "metadata": {},
   "source": [
    "- RNNの課題（勾配消失）  \n",
    "時間的なつながりが増えると、通常のNNで層の数が増えたときと同様に勾配消失が起こる（微小量を多数掛け合わせることになる）  \n",
    "例えば勾配消失しやすい活性化関数として、sigmoid関数がある"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "113332f2-e6e7-46ba-ba4a-81baeffabc36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 参考：シグモイド関数の微分の最大値\n",
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "def d_sigmoid(x):\n",
    "    return sigmoid(x) * (1-sigmoid(x))\n",
    "\n",
    "d_sigmoid(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d20b2373-3d6e-462a-bb60-9643998eb5c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x183603d8d08>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# x=0で最大になることを図的に確認\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "xs = np.arange(-5,5,0.1)\n",
    "ys = d_sigmoid(xs)\n",
    "plt.plot(xs,ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b26051ec-f2b9-4e69-aa4c-baf8340de700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 演習チャレンジのコード例  \n",
    "def gradient_clipping(grad, threshold):\n",
    "    \"\"\"\n",
    "    勾配爆発を防ぐために、勾配のノルムに閾値を設ける\n",
    "    \"\"\"\n",
    "    norm = np.linalg.norm(grad)\n",
    "    rate = threshold / norm\n",
    "    if rate < 1:\n",
    "        return grad * rate\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd7d298-b975-4df6-bbbb-a1d10581b223",
   "metadata": {},
   "source": [
    "- LSTMとは  \n",
    "RNNの一種。中間層としてCECという層を持つ。  \n",
    "CECは過去の時間情報を「記憶する」ものとして取り入れる。\n",
    "勾配消失の原因は、勾配が1より小さいことに起因するので、勾配が1であればよい。  \n",
    "しかし、CECは「記憶」する機能しか持たないため、学習する機能を持たない。  \n",
    "そこで、入力ゲートと出力ゲートを組み合わせて使う。  \n",
    "- 入力ゲート  \n",
    "入力ゲートは、CECへの入力を加工し、どういった情報を「記憶」すればよいのかを調整する。  \n",
    "入力ゲートは、学習することができる。  \n",
    "パラメータとして、$W_i,U_i$を持つ。今回の入力および前回の出力をどのくらい使うかを支配するパラメータ。\n",
    "- 出力ゲート  \n",
    "CECからの出力を、どのように加工すれば、「記憶」をうまく使えるのかを調整する。  \n",
    "出力ゲートは、学習することができる。  \n",
    "- 忘却ゲート  \n",
    "CECは情報の損失なく、過去の時間情報を「記憶」しているので、古すぎる情報を使ってしまうことがある。  \n",
    "その対策として、忘却ゲートを用いて、ある程度古い情報は捨てるように調整する。  \n",
    "- 覗き穴結合  \n",
    "現在のCECの状況も入出力、忘却ゲートの計算に利用するというもの。  \n",
    "ただし、実際にはあまり効果はでなかった。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8203cd96-4597-45b1-9f1b-838edd1d7c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm(x, prev_h, prev_c, W, U, b):\n",
    "    \"\"\"\n",
    "    LSTMにおける順伝播の計算\n",
    "    \"\"\"\n",
    "    # _activationは活性化関数を別に定義する。\n",
    "    lstm_in = _activation(x.dot(W.T) + prev_h.dot(U.T) + b)\n",
    "    a, i, f, o = np.hsplit(lstm_in, 4)\n",
    "    \n",
    "    a = np.tanh(a)\n",
    "    input_gate = _sigmoid(i)\n",
    "    forget_gate = _sigmoid(f)\n",
    "    output_gate = _sigmoid(o)\n",
    "    \n",
    "    # 状態の更新\n",
    "    c = input_gate * a + forget_gate * c\n",
    "    h = output_gate * np.tanh(c)\n",
    "    return c, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5b22f77-ee31-40c6-a892-5e16aae84422",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# predict wordを以下に実装する。\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import re\n",
    "import glob\n",
    "import collections\n",
    "import random\n",
    "import pickle\n",
    "import time\n",
    "import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3083e9c3-548c-4ef2-b9b9-3f428e94578b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Corpus:\n",
    "    def __init__(self):\n",
    "        self.unknown_word_symbol = \"<???>\"\n",
    "        self.unknown_word_threshold = 3\n",
    "        self.corpus_file = \"./corpus/**/*.txt\"\n",
    "        self.corpus_encoding = \"utf-8\"\n",
    "        self.dictionary_filename = \"./data_for_predict/word_dict.dic\"\n",
    "        self.chunk_size = 5\n",
    "        self.load_dict()\n",
    "        \n",
    "        words = []\n",
    "        for filename in glob.glob(self.corpus_file, recursive=True):\n",
    "            with open(filename, \"r\", encoding=self.corpus_encoding) as f:\n",
    "                text = f.read()\n",
    "                text = text.lower().replace(\"\\n\", \" \")\n",
    "                text = re.sub(r\"[^a-z '\\-]\", \"\", text)\n",
    "                text = re.sub(r\"[ ]+\", \" \", text)\n",
    "                \n",
    "                words = [ word for word in text.split() if not word.startswith(\"-\")]\n",
    "                \n",
    "        self.data_n = len(words) - self.chunk_size\n",
    "        self.data = self.seq_to_matrix(words)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afraid-aruba",
   "metadata": {},
   "source": [
    "# Section3 : GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesser-cannon",
   "metadata": {},
   "source": [
    "- GRU：LSTMの問題を解決  \n",
    "LSTMはパラメータが多すぎた。  \n",
    "計算負荷を減らす工夫として、GRUが考え出された。\n",
    "リセットゲートと更新ゲートによって、層を表現する。  \n",
    "LSTMよりGRUの方が、パラメータが少なく、計算量が少ない。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c590fee1-e6e8-4245-ab1b-d25967ba2dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 演習チャレンジの実装\n",
    "def gru(x, h, W_r, U_r, W_z, U_z, W, U):\n",
    "    \"\"\"\n",
    "    GRUにおける順伝播\n",
    "    \"\"\"\n",
    "    r = _sigmoid(x.dot(W_r.T) + h.dot(U_r.T))\n",
    "    z = _sigmoid(x.dot(W_z.T) + h.dot(U_z.T))\n",
    "    \n",
    "    h_bar = np.tanh(x.dot(W.T) + (r * h).dot(U.T))\n",
    "    h_new = (1-z) * h + z * h_bar\n",
    "    return h_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "healthy-gregory",
   "metadata": {},
   "source": [
    "## Section4 : 双方向RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "editorial-smoke",
   "metadata": {},
   "source": [
    "- 双方向RNN  \n",
    "過去の情報だけでなく、未来の情報を加味することで、制度を向上させるためのモデル。  \n",
    "実用例として、文章の推敲や、機械翻訳がる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4ec4fc-ad8b-41d4-ac17-d92b9fb6f414",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bidirectional_rnn_net(xs, W_f, U_f, W_b, U_b, V):\n",
    "    \"\"\"\n",
    "    双方向RNNの順伝播\n",
    "    \"\"\"\n",
    "    xs_f = np.zeros_like(xs) # 未来へ向かう方向\n",
    "    xs_b = np.zeros_like(xs) # 過去へ向かう方向\n",
    "    for i, x in enumerate(xs):\n",
    "        xs_f[i] = x\n",
    "        xs_b[i] = x[::-1]\n",
    "    hs_f = _rnn(xs_f, W_f, U_f)\n",
    "    hs_b = _rnn(xs_b, W_b, U_b)\n",
    "    hs = [np.concatenate([h_f, h_b[::-1]], axis = 1) for h_f, h_b in zip(hs_f, hs_b)] # 同一のタイミング同士がそろうように結合する。\n",
    "    ys = hs.dot(V.T)\n",
    "    return ys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "radio-functionality",
   "metadata": {},
   "source": [
    "## Section5 : Seq2Seq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatal-liability",
   "metadata": {},
   "source": [
    "- Seq2Seq  \n",
    "二つのネットワーク（NNの種類は問わない）をつなげたもの。  \n",
    "機械翻訳で使われる。  \n",
    "最初の解釈側のSeqをEncoder、新しい構造を作る側をDecoderと呼ぶ。\n",
    "- embedding  \n",
    "文章をone-hotで考えると、成分数が非常に多く（10000以上）なってしまう。  \n",
    "対策として、特徴量を抽出して、似たような単語は似たようなベクトルになるような操作（=embedding）が行われる。  \n",
    "- MLM(Masked Language Model)  \n",
    "embeddingの一種。  \n",
    "文章中のある単語を消して、その単語がなにであるのかを他の単語から推測する。  \n",
    "- Decoder RNN  \n",
    "Encoderの解釈したベクトルを元に出力を生成する。  \n",
    "- 問題点  \n",
    "seq2seqだと、文脈を解釈することができない。  \n",
    "- HRED  \n",
    "文章をつなげて、文脈を解釈できるようにしたもの。  \n",
    "RNNの中にRNNをつなげたようなもの。  \n",
    "ただし、短い文を返答しがちになる。  \n",
    "- VHRED  \n",
    "HREDの問題点に対策した応用。オートエンコーダを利用して、「当たり障りのない回答」以外を出しやすくしている。  \n",
    "- オートエンコーダ  \n",
    "教師なし学習の一つ。  \n",
    "入力データから潜在変数zに変換するニューラルネットワークをEncoder、逆に潜在変数zをインプットとして元画像を復元するニューラルネットワークをDecoderとしてもつ。  \n",
    "要するに、変数間の関係性を抽出しているため、次元削減を行うことができる。  \n",
    "- VAE  \n",
    "オートエンコーダの潜在変数zに確率分布 z~N(0,1)(正規分布）を仮定したもの。  \n",
    "zに対して、小さなノイズを加える形で学習を進める。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6376698f-c9a2-4747-a1b9-8084b23eb248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 演習チャレンジの実装\n",
    "def encode(words, E, W, U, b):\n",
    "    \"\"\"\n",
    "    文章を特徴量に変換する\n",
    "    \"\"\"\n",
    "    hidden_size = W.shape[0]\n",
    "    h = np.zeros(hidden_size)\n",
    "    for w in words:\n",
    "        e = E.tod(w)\n",
    "        h = _activation(W.dot(e) + U.dot(h) + b)\n",
    "    return h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "functioning-gregory",
   "metadata": {},
   "source": [
    "## Section6 : Word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hollywood-toner",
   "metadata": {},
   "source": [
    "- Word2Vec\n",
    "単語をベクトルにする方法の一つ。embeddingの一つ。  \n",
    "まず文章の単語について、onehotベクトルを作る。\n",
    "文章を用いた教師なし学習で、変換行列を取得する。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cellular-national",
   "metadata": {},
   "source": [
    "## Section7 : Attention Mechanism"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pharmaceutical-reunion",
   "metadata": {},
   "source": [
    "- Attention Mechanism  \n",
    "Seq2Seqは長い文章への対応が難しい。一定の長さのベクトルに落とし込まれてしまうから。  \n",
    "文章の中で特に重要な単語を自力で発見する仕組み。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
